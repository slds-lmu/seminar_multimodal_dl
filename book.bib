@ARTICLE{Glide2021,
  AUTHOR = {Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  URL = {https://arxiv.org/abs/2112.10741},
  YEAR = {2021},
  EPRINT = {2112.10741},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {{GLIDE:} Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
}

@ARTICLE{Lu2020,
  AUTHOR = {Yu, Jun and Li, Jing and Yu, Zhou and Huang, Qingming},
  YEAR = {2020},
  DOI = {10.1109/TCSVT.2019.2947482},
  JOURNALTITLE = {IEEE Transactions on Circuits and Systems for Video Technology},
  NUMBER = {12},
  PAGES = {4467--4480},
  TITLE = {Multimodal Transformer With Multi-View Visual Representation for Image Captioning},
  VOLUME = {30},
}

@MISC{Fedus2021,
  AUTHOR = {Fedus, William and Zoph, Barret and Shazeer, Noam},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2101.03961},
  YEAR = {2021},
  DOI = {10.48550/ARXIV.2101.03961},
  KEYWORDS = {Machine Learning (cs.LG),Artificial Intelligence (cs.AI),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
}

@MISC{Mustafa2022,
  AUTHOR = {Mustafa, Basil and Riquelme, Carlos and Puigcerver, Joan and Jenatton, Rodolphe and Houlsby, Neil},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2206.02770},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2206.02770},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts},
}

@ARTICLE{Carion2020,
  AUTHOR = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  URL = {https://arxiv.org/abs/2005.12872},
  YEAR = {2020},
  EPRINT = {2005.12872},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {End-to-End Object Detection with Transformers},
}

@MISC{Crawshaw2020,
  AUTHOR = {Crawshaw, Michael},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2009.09796},
  YEAR = {2020},
  DOI = {10.48550/ARXIV.2009.09796},
  KEYWORDS = {Machine Learning (cs.LG),Computer Vision and Pattern Recognition (cs.CV),Machine Learning (stat.ML),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Multi-Task Learning with Deep Neural Networks: A Survey},
}

@ARTICLE{Baltrusaitis2019,
  AUTHOR = {Baltrušaitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  YEAR = {2019},
  DOI = {10.1109/TPAMI.2018.2798607},
  JOURNALTITLE = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  NUMBER = {2},
  PAGES = {423--443},
  TITLE = {Multimodal Machine Learning: A Survey and Taxonomy},
  VOLUME = {41},
}

@ARTICLE{Kaiser2017,
  AUTHOR = {Kaiser, Lukasz and Gomez, Aidan N. and Shazeer, Noam and Vaswani, Ashish and Parmar, Niki and Jones, Llion and Uszkoreit, Jakob},
  URL = {https://arxiv.org/pdf/1706.05137.pdf},
  YEAR = {2017},
  JOURNALTITLE = {arXiv},
  TITLE = {One Model To Learn Them All},
}

@INPROCEEDINGS{Hu2021,
  AUTHOR = {Hu, Ronghang and Singh, Amanpreet},
  BOOKTITLE = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  YEAR = {2021},
  DOI = {10.1109/ICCV48922.2021.00147},
  PAGES = {1419--1429},
  TITLE = {UniT: Multimodal Multitask Learning with a Unified Transformer},
}

@MISC{Li2019,
  AUTHOR = {Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1908.03557},
  YEAR = {2019},
  DOI = {10.48550/ARXIV.1908.03557},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Computation and Language (cs.CL),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {VisualBERT: A Simple and Performant Baseline for Vision and Language},
}

@ONLINE{Dean21,
  AUTHOR = {Dean, Jeff},
  URL = {https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/},
  YEAR = {2021},
  TITLE = {Introducing Pathways: A next-generation AI architecture},
}

@ARTICLE{Krishna2017,
  AUTHOR = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A. and Bernstein, Michael S. and Fei-Fei, Li},
  LOCATION = {USA},
  PUBLISHER = {Kluwer Academic Publishers},
  URL = {https://DOI.org/10.1007/s11263-016-0981-7},
  YEAR = {2017},
  DOI = {10.1007/s11263-016-0981-7},
  ISSN = {0920-5691},
  JOURNALTITLE = {Int. J. Comput. Vision},
  KEYWORDS = {Language,Relationships,Attributes,Question answering,Scene graph,Crowdsourcing,Computer vision,Knowledge,Image,Objects,Dataset},
  NUMBER = {1},
  PAGES = {32--73},
  TITLE = {Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  VOLUME = {123},
}

@INPROCEEDINGS{Wang2022,
  AUTHOR = {Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  EDITOR = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  PUBLISHER = {PMLR},
  URL = {https://proceedings.mlr.press/v162/wang22al.html},
  BOOKTITLE = {Proceedings of the 39th International Conference on Machine Learning},
  YEAR = {2022},
  FILE = {https://proceedings.mlr.press/v162/wang22al/wang22al.pdf},
  PAGES = {23318--23340},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {{OFA}: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework},
  VOLUME = {162},
}

@MISC{Reed2022,
  AUTHOR = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and Eccles, Tom and Bruce, Jake and Razavi, Ali and Edwards, Ashley and Heess, Nicolas and Chen, Yutian and Hadsell, Raia and Vinyals, Oriol and Bordbar, Mahyar and de Freitas, Nando},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2205.06175},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2205.06175},
  KEYWORDS = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),Machine Learning (cs.LG),Robotics (cs.RO),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {A Generalist Agent},
}

@ARTICLE{Chowdhery2022,
  AUTHOR = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  URL = {https://arxiv.org/abs/2204.02311},
  YEAR = {2022},
  JOURNALTITLE = {arxiv:2204.02311},
  TITLE = {PaLM: Scaling Language Modeling with Pathways},
}

@MISC{Yu2022,
  AUTHOR = {Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and Hutchinson, Ben and Han, Wei and Parekh, Zarana and Li, Xin and Zhang, Han and Baldridge, Jason and Wu, Yonghui},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2206.10789},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2206.10789},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
}

@INPROCEEDINGS{Fernando2017,
  AUTHOR = {Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A. and Pritzel, Alexander and Wierstra, Daan},
  URL = {https://arxiv.org/abs/1701.08734},
  YEAR = {2017},
  TITLE = {PathNet: Evolution Channels Gradient Descent in Super Neural Networks},
}

@INPROCEEDINGS{He2016b,
  AUTHOR = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  EDITOR = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  LOCATION = {Cham},
  PUBLISHER = {Springer International Publishing},
  BOOKTITLE = {Computer Vision -- ECCV 2016},
  YEAR = {2016},
  ISBN = {978-3-319-46493-0},
  PAGES = {630--645},
  TITLE = {Identity Mappings in Deep Residual Networks},
}

@INPROCEEDINGS{Dean20,
  AUTHOR = {Dean, Jeffrey},
  BOOKTITLE = {2020 IEEE International Solid- State Circuits Conference - (ISSCC)},
  YEAR = {2020},
  DOI = {10.1109/ISSCC19947.2020.9063049},
  PAGES = {8--14},
  TITLE = {1.1 The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design},
}

@REPORT{Lewkowycz2022,
  AUTHOR = {Lewkowycz, Aitor and Andreassen, Anders and Dohan, David Martin and Dyer, Ethan S and Michalewski, Henryk and Ramasesh, Vinay and Slone, Ambrose and Anil, Cem and Schlag, Imanol and Gutman-Solo, Theo and Wu, Yuhuai and Neyshabur, Behnam and Gur-Ari, Guy and Misra, Vedant},
  URL = {https://arxiv.org/abs/2206.14858},
  YEAR = {2022},
  TITLE = {Solving Quantitative Reasoning Problems with Language Models},
  TYPE = {techreport},
}

@INPROCEEDINGS{Riquelme2021,
  AUTHOR = {Riquelme, Carlos and Puigcerver, Joan and Mustafa, Basil and Neumann, Maxim and Jenatton, Rodolphe and Susano Pinto, André and Keysers, Daniel and Houlsby, Neil},
  EDITOR = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman},
  PUBLISHER = {Curran Associates, Inc.},
  URL = {https://proceedings.neurips.cc/paper/2021/file/48237d9f2dea8c74c2a72126cf63d933-Paper.pdf},
  BOOKTITLE = {Advances in Neural Information Processing Systems},
  YEAR = {2021},
  PAGES = {8583--8595},
  TITLE = {Scaling Vision with Sparse Mixture of Experts},
  VOLUME = {34},
}

@MISC{Gesmundo2022a,
  AUTHOR = {Gesmundo, Andrea and Dean, Jeff},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2205.10937},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2205.10937},
  KEYWORDS = {Machine Learning (cs.LG),Artificial Intelligence (cs.AI),Computer Vision and Pattern Recognition (cs.CV),Neural and Evolutionary Computing (cs.NE),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems},
}

@ARTICLE{Steiner2021,
  AUTHOR = {Steiner, Andreas and Kolesnikov, Alexander and Zhai, Xiaohua and Wightman, Ross and Uszkoreit, Jakob and Beyer, Lucas},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2106.10270},
  YEAR = {2021},
  DOI = {10.48550/ARXIV.2106.10270},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Artificial Intelligence (cs.AI),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers},
}

@INPROCEEDINGS{Houlsby2019,
  AUTHOR = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  EDITOR = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  PUBLISHER = {PMLR},
  URL = {https://proceedings.mlr.press/v97/houlsby19a.html},
  BOOKTITLE = {Proceedings of the 36th International Conference on Machine Learning},
  YEAR = {2019},
  FILE = {http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf},
  PAGES = {2790--2799},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {Parameter-Efficient Transfer Learning for {NLP}},
  VOLUME = {97},
}

@INPROCEEDINGS{Rebuffi2017,
  AUTHOR = {Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  EDITOR = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  PUBLISHER = {Curran Associates, Inc.},
  URL = {https://proceedings.neurips.cc/paper/2017/file/e7b24b112a44fdd9ee93bdf998c6ca0e-Paper.pdf},
  BOOKTITLE = {Advances in Neural Information Processing Systems},
  YEAR = {2017},
  TITLE = {Learning multiple visual domains with residual adapters},
  VOLUME = {30},
}

@MISC{Bilen2017,
  AUTHOR = {Bilen, Hakan and Rebuffi, SSylvestre and Jakab, Tomas},
  YEAR = {2017},
  TITLE = {Visual domain decathlon},
}

@ARTICLE{Doerr2021,
  AUTHOR = {Doerr, Benjamin and Neumann, Frank},
  LOCATION = {New York, NY, USA},
  PUBLISHER = {Association for Computing Machinery},
  URL = {https://doi.org/10.1145/3472304},
  YEAR = {2021},
  DOI = {10.1145/3472304},
  ISSN = {2688-299X},
  JOURNALTITLE = {ACM Trans. Evol. Learn. Optim.},
  KEYWORDS = {parameterized complexity,discrete optimization,evolutionary algorithms,estimation of distribution algorithms,Theory},
  NUMBER = {4},
  TITLE = {A Survey on Recent Progress in the Theory of Evolutionary Algorithms for Discrete Optimization},
  VOLUME = {1},
}

@ARTICLE{Baeck1993,
  AUTHOR = {Bäck, Thomas and Schwefel, Hans-Paul},
  YEAR = {1993},
  DOI = {10.1162/evco.1993.1.1.1},
  JOURNALTITLE = {Evolutionary Computation},
  NUMBER = {1},
  PAGES = {1--23},
  TITLE = {An Overview of Evolutionary Algorithms for Parameter Optimization},
  VOLUME = {1},
}

@MISC{Hinton2015,
  AUTHOR = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1503.02531},
  YEAR = {2015},
  DOI = {10.48550/ARXIV.1503.02531},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),Neural and Evolutionary Computing (cs.NE),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Distilling the Knowledge in a Neural Network},
}

@INPROCEEDINGS{Shaazer2017,
  AUTHOR = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  URL = {https://openreview.net/pdf?id=B1ckMDqlg},
  YEAR = {2017},
  TITLE = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
}

@ARTICLE{Jordan1994,
  AUTHOR = {Jordan, Michael I. and Jacobs, Robert A.},
  YEAR = {1994},
  DOI = {10.1162/neco.1994.6.2.181},
  JOURNALTITLE = {Neural Computation},
  NUMBER = {2},
  PAGES = {181--214},
  TITLE = {Hierarchical Mixtures of Experts and the EM Algorithm},
  VOLUME = {6},
}

@ARTICLE{Jacobs1991,
  AUTHOR = {Jacobs, Robert A. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},
  YEAR = {1991},
  DOI = {10.1162/neco.1991.3.1.79},
  JOURNALTITLE = {Neural Computation},
  NUMBER = {1},
  PAGES = {79--87},
  TITLE = {Adaptive Mixtures of Local Experts},
  VOLUME = {3},
}

@INPROCEEDINGS{sennrich-etal-2016-neural,
  AUTHOR = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  LOCATION = {Berlin, Germany},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/P16-1162},
  BOOKTITLE = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  YEAR = {2016},
  DOI = {10.18653/v1/P16-1162},
  PAGES = {1715--1725},
  TITLE = {Neural Machine Translation of Rare Words with Subword Units},
}

@INPROCEEDINGS{pmlr-v139-ramesh21a,
  AUTHOR = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  EDITOR = {Meila, Marina and Zhang, Tong},
  PUBLISHER = {PMLR},
  URL = {https://proceedings.mlr.press/v139/ramesh21a.html},
  BOOKTITLE = {Proceedings of the 38th International Conference on Machine Learning},
  YEAR = {2021},
  FILE = {http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf},
  PAGES = {8821--8831},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {Zero-Shot Text-to-Image Generation},
  VOLUME = {139},
}

@ARTICLE{ResNet,
  AUTHOR = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  URL = {http://arxiv.org/abs/1512.03385},
  YEAR = {2015},
  EPRINT = {1512.03385},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Deep Residual Learning for Image Recognition},
}

@INPROCEEDINGS{mccoco,
  AUTHOR = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C. Lawrence},
  PUBLISHER = {Springer International Publishing},
  BOOKTITLE = {Computer Vision -- ECCV 2014},
  YEAR = {2014},
  ISBN = {978-3-319-10602-1},
  PAGES = {740--755},
  TITLE = {Microsoft COCO: Common Objects in Context},
}

@INPROCEEDINGS{kudo-richardson-2018-sentencepiece,
  AUTHOR = {Kudo, Taku and Richardson, John},
  LOCATION = {Brussels, Belgium},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/D18-2012},
  BOOKTITLE = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  YEAR = {2018},
  DOI = {10.18653/v1/D18-2012},
  PAGES = {66--71},
  TITLE = {{S}entence{P}iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing},
}

@ARTICLE{Devlin2018,
  AUTHOR = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  YEAR = {2018},
  EPRINT = {1810.04805},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1810.04805v2:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
}

@ARTICLE{brown2020language,
  AUTHOR = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  YEAR = {2020},
  JOURNALTITLE = {Advances in neural information processing systems},
  PAGES = {1877--1901},
  TITLE = {Language models are few-shot learners},
  VOLUME = {33},
}

@ARTICLE{ImageNet,
  AUTHOR = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
  LOCATION = {USA},
  PUBLISHER = {Kluwer Academic Publishers},
  URL = {https://doi.org/10.1007/s11263-015-0816-y},
  YEAR = {2015},
  DOI = {10.1007/s11263-015-0816-y},
  ISSN = {0920-5691},
  JOURNALTITLE = {Int. J. Comput. Vision},
  KEYWORDS = {Benchmark,Object detection,Large-scale,Object recognition,Dataset},
  NUMBER = {3},
  PAGES = {211--252},
  TITLE = {ImageNet Large Scale Visual Recognition Challenge},
  VOLUME = {115},
}

@ARTICLE{dosovitskiy2020image,
  AUTHOR = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2010.11929},
  TITLE = {An image is worth 16x16 words: Transformers for image recognition at scale},
}

@ARTICLE{vaswani2017attention,
  AUTHOR = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {Ł}ukasz and Polosukhin, Illia},
  YEAR = {2017},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Attention is all you need},
  VOLUME = {30},
}

@INPROCEEDINGS{deng2009imagenet,
  AUTHOR = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  ORGANIZATION = {Ieee},
  BOOKTITLE = {2009 IEEE conference on computer vision and pattern recognition},
  YEAR = {2009},
  PAGES = {248--255},
  TITLE = {Imagenet: A large-scale hierarchical image database},
}

@ARTICLE{parti,
  AUTHOR = {Yu, Jiahui and Xu, Yuanzhong and Koh, Jing and Luong, Thang and Baid, Gunjan and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu and Hutchinson, Ben and Han, Wei and Parekh, Zarana and Li, Xin and Zhang, Han and Baldridge, Jason and Wu, Yonghui},
  YEAR = {2022},
  DOI = {10.48550/arXiv.2206.10789},
  TITLE = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
}

@INPROCEEDINGS{lewis-etal-2020-bart,
  AUTHOR = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
  LOCATION = {Online},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/2020.acl-main.703},
  BOOKTITLE = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  YEAR = {2020},
  DOI = {10.18653/v1/2020.acl-main.703},
  PAGES = {7871--7880},
  TITLE = {{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
}

@ARTICLE{atari,
  AUTHOR = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  LOCATION = {El Segundo, CA, USA},
  PUBLISHER = {AI Access Foundation},
  YEAR = {2013},
  ISSN = {1076-9757},
  JOURNALTITLE = {J. Artif. Int. Res.},
  NUMBER = {1},
  PAGES = {253--279},
  TITLE = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
  VOLUME = {47},
}

@ONLINE{darkMatter,
  AUTHOR = {Yann, Lecun and Ishan, Misra},
  URL = {https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/},
  YEAR = {2021},
  TITLE = {Self-supervised learning: The dark matter of intelligence},
  URLDATE = {2022-06-26},
}

@ONLINE{redditUsers,
  AUTHOR = {MICHAEL BARTHEL, GALEN STOCKING, JESSE HOLCOMB and MITCHELL, AMY},
  URL = {https://www.pewresearch.org/journalism/2016/02/25/reddit-news-users-more-likely-to-be-male-young-and-digital-in-their-news-preferences/},
  YEAR = {2016},
  TITLE = {Reddit news users more likely to be male, young and digital in their news preferences},
  URLDATE = {2022-08-07},
}

@ONLINE{coco_eval,
  AUTHOR = {Mircosoft},
  URL = {https://cocodataset.org/#detection-eval},
  YEAR = {2019},
  TITLE = {Evaluate:Detection},
  URLDATE = {2022-07-09},
}

@ONLINE{unsupBrain,
  AUTHOR = {Mineault, Patrick},
  URL = {https://xcorr.net/2021/12/31/2021-in-review-unsupervised-brain-models/},
  YEAR = {2021},
  TITLE = {Unsupervised models of the brain},
  URLDATE = {2022-06-26},
}

@ARTICLE{zhuang2021unsupervised,
  AUTHOR = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C and DiCarlo, James J and Yamins, Daniel LK},
  PUBLISHER = {National Acad Sciences},
  YEAR = {2021},
  JOURNALTITLE = {Proceedings of the National Academy of Sciences},
  NUMBER = {3},
  PAGES = {e2014196118},
  TITLE = {Unsupervised neural network models of the ventral visual stream},
  VOLUME = {118},
}

@ARTICLE{liu2019roberta,
  AUTHOR = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  YEAR = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1907.11692},
  TITLE = {Roberta: A robustly optimized bert pretraining approach},
}

@ARTICLE{bromley1993signature,
  AUTHOR = {Bromley, Jane and Guyon, Isabelle and LeCun, Yann and Säckinger, Eduard and Shah, Roopak},
  YEAR = {1993},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Signature verification using a" siamese" time delay neural network},
  VOLUME = {6},
}

@INPROCEEDINGS{caron2021emerging,
  AUTHOR = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jégou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  BOOKTITLE = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  YEAR = {2021},
  PAGES = {9650--9660},
  TITLE = {Emerging properties in self-supervised vision transformers},
}

@INPROCEEDINGS{mahajan2018exploring,
  AUTHOR = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  BOOKTITLE = {Proceedings of the European conference on computer vision (ECCV)},
  YEAR = {2018},
  PAGES = {181--196},
  TITLE = {Exploring the limits of weakly supervised pretraining},
}

@ARTICLE{kolesnikov2019large,
  AUTHOR = {Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  PUBLISHER = {arXiv},
  YEAR = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1912.11370},
  NUMBER = {8},
  TITLE = {Large scale learning of general visual representations for transfer},
  VOLUME = {2},
}

@ARTICLE{rajpurkar2016squad,
  AUTHOR = {Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  YEAR = {2016},
  JOURNALTITLE = {arXiv preprint arXiv:1606.05250},
  TITLE = {Squad: 100,000+ questions for machine comprehension of text},
}

@ARTICLE{rajpurkar2018know,
  AUTHOR = {Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  YEAR = {2018},
  JOURNALTITLE = {arXiv preprint arXiv:1806.03822},
  TITLE = {Know what you don't know: Unanswerable questions for SQuAD},
}

@ARTICLE{srivastava2022beyond,
  AUTHOR = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adrià and others},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2206.04615},
  TITLE = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
}

@ARTICLE{bowman2021will,
  AUTHOR = {Bowman, Samuel R and Dahl, George E},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2104.02145},
  TITLE = {What Will it Take to Fix Benchmarking in Natural Language Understanding?},
}

@ARTICLE{goodfellow2014explaining,
  AUTHOR = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  YEAR = {2014},
  JOURNALTITLE = {arXiv preprint arXiv:1412.6572},
  TITLE = {Explaining and harnessing adversarial examples},
}

@INPROCEEDINGS{recht2019imagenet,
  AUTHOR = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  ORGANIZATION = {PMLR},
  BOOKTITLE = {International Conference on Machine Learning},
  YEAR = {2019},
  PAGES = {5389--5400},
  TITLE = {Do imagenet classifiers generalize to imagenet?},
}

@ARTICLE{beyer2020we,
  AUTHOR = {Beyer, Lucas and Hénaff, Olivier J and Kolesnikov, Alexander and Zhai, Xiaohua and Oord, Aäron van den},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2006.07159},
  TITLE = {Are we done with imagenet?},
}

@ARTICLE{li2022mask,
  AUTHOR = {Li, Feng and Zhang, Hao and Liu, Shilong and Zhang, Lei and Ni, Lionel M and Shum, Heung-Yeung and others},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2206.02777},
  TITLE = {Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation},
}

@INPROCEEDINGS{koehn2005europarl,
  AUTHOR = {Koehn, Philipp},
  BOOKTITLE = {Proceedings of machine translation summit x: papers},
  YEAR = {2005},
  PAGES = {79--86},
  TITLE = {Europarl: A parallel corpus for statistical machine translation},
}

@MISC{Gokaslan2019OpenWeb,
  AUTHOR = {Gokaslan, Aaron and Cohen, Vanya},
  YEAR = {2019},
  TITLE = {OpenWebText Corpus},
}

@ARTICLE{xue2020mt5,
  AUTHOR = {Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2010.11934},
  TITLE = {mT5: A massively multilingual pre-trained text-to-text transformer},
}

@ARTICLE{wenzek2019ccnet,
  AUTHOR = {Wenzek, Guillaume and Lachaux, Marie-Anne and Conneau, Alexis and Chaudhary, Vishrav and Guzmán, Francisco and Joulin, Armand and Grave, Edouard},
  YEAR = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1911.00359},
  TITLE = {Ccnet: Extracting high quality monolingual datasets from web crawl data},
}

@ARTICLE{bandy2021addressing,
  AUTHOR = {Bandy, Jack and Vincent, Nicholas},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2105.05241},
  TITLE = {Addressing" documentation debt" in machine learning research: A retrospective datasheet for bookcorpus},
}

@ARTICLE{gao2017knowledge,
  AUTHOR = {Gao, Jiyang and Li, Zhen and Nevatia, Ram and others},
  YEAR = {2017},
  JOURNALTITLE = {arXiv preprint arXiv:1711.07607},
  TITLE = {Knowledge concentration: Learning 100k object classifiers in a single CNN},
}

@INPROCEEDINGS{shao2019objects365,
  AUTHOR = {Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
  BOOKTITLE = {Proceedings of the IEEE/CVF international conference on computer vision},
  YEAR = {2019},
  PAGES = {8430--8439},
  TITLE = {Objects365: A large-scale, high-quality dataset for object detection},
}

@ARTICLE{yuan2022wudaomm,
  AUTHOR = {Yuan, Sha and Shuai, Zhao and Jiahong, Leng and Zhao, Xue and Hanyu, Zhao and Jie, Tang},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2203.11480},
  TITLE = {WuDaoMM: A large-scale Multi-Modal Dataset for Pre-training models},
}

@INPROCEEDINGS{srinivasan2021wit,
  AUTHOR = {Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  BOOKTITLE = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  YEAR = {2021},
  PAGES = {2443--2449},
  TITLE = {Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning},
}

@ARTICLE{tiedemann2018emerging,
  AUTHOR = {Tiedemann, Jörg},
  YEAR = {2018},
  JOURNALTITLE = {arXiv preprint arXiv:1802.00273},
  TITLE = {Emerging language spaces learned from massively multilingual corpora},
}

@ARTICLE{mayer2014creating,
  AUTHOR = {Mayer, Thomas and Cysouw, Michael},
  YEAR = {2014},
  JOURNALTITLE = {Oceania},
  NUMBER = {273},
  PAGES = {40},
  TITLE = {Creating a massively parallel Bible corpus},
  VOLUME = {135},
}

@INPROCEEDINGS{zellers2019recognition,
  AUTHOR = {Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  BOOKTITLE = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  YEAR = {2019},
  PAGES = {6720--6731},
  TITLE = {From recognition to cognition: Visual commonsense reasoning},
}

@INPROCEEDINGS{antol2015vqa,
  AUTHOR = {Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  BOOKTITLE = {Proceedings of the IEEE international conference on computer vision},
  YEAR = {2015},
  PAGES = {2425--2433},
  TITLE = {Vqa: Visual question answering},
}

@INPROCEEDINGS{zhang2016yin,
  AUTHOR = {Zhang, Peng and Goyal, Yash and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  BOOKTITLE = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  YEAR = {2016},
  PAGES = {5014--5022},
  TITLE = {Yin and yang: Balancing and answering binary visual questions},
}

@INPROCEEDINGS{goyal2017making,
  AUTHOR = {Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  BOOKTITLE = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  YEAR = {2017},
  PAGES = {6904--6913},
  TITLE = {Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
}

@INPROCEEDINGS{hudson2019gqa,
  AUTHOR = {Hudson, Drew A and Manning, Christopher D},
  BOOKTITLE = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  YEAR = {2019},
  PAGES = {6700--6709},
  TITLE = {Gqa: A new dataset for real-world visual reasoning and compositional question answering},
}

@ARTICLE{shekhar2017foil,
  AUTHOR = {Shekhar, Ravi and Pezzelle, Sandro and Klimovich, Yauhen and Herbelot, Aurélie and Nabi, Moin and Sangineto, Enver and Bernardi, Raffaella},
  YEAR = {2017},
  JOURNALTITLE = {arXiv preprint arXiv:1705.01359},
  TITLE = {Foil it! find one mismatch between image and language caption},
}

@ARTICLE{ribeiro2020beyond,
  AUTHOR = {Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2005.04118},
  TITLE = {Beyond accuracy: Behavioral testing of NLP models with CheckList},
}

@INPROCEEDINGS{parcalabescu-etal-2022-valse,
  AUTHOR = {Parcalabescu, Letitia and Cafagna, Michele and Muradjan, Lilitta and Frank, Anette and Calixto, Iacer and Gatt, Albert},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/2022.acl-long.567},
  BOOKTITLE = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  YEAR = {2022},
  PAGES = {8253--8280},
  TITLE = {{VALSE}: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena},
}

@ARTICLE{sheng2019woman,
  AUTHOR = {Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  YEAR = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1909.01326},
  TITLE = {The woman worked as a babysitter: On biases in language generation},
}

@INPROCEEDINGS{dhamala2021bold,
  AUTHOR = {Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
  BOOKTITLE = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  YEAR = {2021},
  PAGES = {862--872},
  TITLE = {Bold: Dataset and metrics for measuring biases in open-ended language generation},
}

@ARTICLE{prabhu2020large,
  AUTHOR = {Prabhu, Vinay Uday and Birhane, Abeba},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2006.16923},
  TITLE = {Large image datasets: A pyrrhic win for computer vision?},
}

@ARTICLE{birhane2021multimodal,
  AUTHOR = {Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2110.01963},
  TITLE = {Multimodal datasets: misogyny, pornography, and malignant stereotypes},
}

@ARTICLE{strubell2019energy,
  AUTHOR = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  YEAR = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1906.02243},
  TITLE = {Energy and policy considerations for deep learning in NLP},
}

@ARTICLE{lottick2019energy,
  AUTHOR = {Lottick, Kadan and Susai, Silvia and Friedler, Sorelle A and Wilson, Jonathan P},
  YEAR = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1911.08354},
  TITLE = {Energy Usage Reports: Environmental awareness as part of algorithmic accountability},
}

@ARTICLE{henderson2020towards,
  AUTHOR = {Henderson, Peter and Hu, Jieru and Romoff, Joshua and Brunskill, Emma and Jurafsky, Dan and Pineau, Joelle},
  YEAR = {2020},
  JOURNALTITLE = {Journal of Machine Learning Research},
  NUMBER = {248},
  PAGES = {1--43},
  TITLE = {Towards the systematic reporting of the energy and carbon footprints of machine learning},
  VOLUME = {21},
}

@INPROCEEDINGS{guo2016ms,
  AUTHOR = {Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
  ORGANIZATION = {Springer},
  BOOKTITLE = {European conference on computer vision},
  YEAR = {2016},
  PAGES = {87--102},
  TITLE = {Ms-celeb-1m: A dataset and benchmark for large-scale face recognition},
}

@INPROCEEDINGS{sun,
  AUTHOR = {Xiao, Jianxiong and Hays, James and Ehinger, Krista A. and Oliva, Aude and Torralba, Antonio},
  BOOKTITLE = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  YEAR = {2010},
  DOI = {10.1109/CVPR.2010.5539970},
  PAGES = {3485--3492},
  TITLE = {SUN database: Large-scale scene recognition from abbey to zoo},
}

@ARTICLE{pascalvoc,
  AUTHOR = {Everingham, Mark and {van Gool}, Luc and Williams, {Christopher K. I.} and Winn, John and Zisserman, Andrew},
  LANGUAGE = {English},
  PUBLISHER = {Springer Netherlands},
  YEAR = {2010},
  DOI = {10.1007/s11263-009-0275-4},
  ISSN = {0920-5691},
  JOURNALTITLE = {International Journal of Computer Vision},
  KEYWORDS = {Benchmark,Database,Object detection,Object recognition},
  NUMBER = {2},
  PAGES = {303--338},
  TITLE = {The PASCAL Visual Object Classes (VOC) Challenge},
  VOLUME = {88},
}

@ARTICLE{WordNet,
  AUTHOR = {Fellbaum, Christiane D.},
  YEAR = {2000},
  JOURNALTITLE = {Language},
  PAGES = {706},
  TITLE = {WordNet : an electronic lexical database},
  VOLUME = {76},
}

@INPROCEEDINGS{Socher10connectingmodalities,
  AUTHOR = {Socher, Richard and Fei-fei, Li},
  BOOKTITLE = {In IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  YEAR = {2010},
  TITLE = {Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora},
}

@ARTICLE{5487377,
  AUTHOR = {Yao, Benjamin Z. and Yang, Xiong and Lin, Liang and Lee, Mun Wai and Zhu, Song-Chun},
  YEAR = {2010},
  DOI = {10.1109/JPROC.2010.2050411},
  JOURNALTITLE = {Proceedings of the IEEE},
  NUMBER = {8},
  PAGES = {1485--1508},
  TITLE = {I2T: Image Parsing to Text Description},
  VOLUME = {98},
}

@INPROCEEDINGS{vinyals,
  AUTHOR = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  YEAR = {2015},
  DOI = {10.1109/CVPR.2015.7298935},
  PAGES = {3156--3164},
  TITLE = {Show and tell: A neural image caption generator},
}

@MISC{karpthy1,
  AUTHOR = {Karpathy, Andrej and Fei-Fei, Li},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1412.2306},
  YEAR = {2014},
  DOI = {10.48550/ARXIV.1412.2306},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Deep Visual-Semantic Alignments for Generating Image Descriptions},
}

@MISC{xu1,
  AUTHOR = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1502.03044},
  YEAR = {2015},
  DOI = {10.48550/ARXIV.1502.03044},
  KEYWORDS = {Machine Learning (cs.LG),Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
}

@MISC{yao1,
  AUTHOR = {Yao, Ting and Pan, Yingwei and Li, Yehao and Mei, Tao},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1809.07041},
  YEAR = {2018},
  DOI = {10.48550/ARXIV.1809.07041},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Exploring Visual Relationship for Image Captioning},
}

@INPROCEEDINGS{devlin-etal-2019-bert,
  AUTHOR = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  LOCATION = {Minneapolis, Minnesota},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/N19-1423},
  YEAR = {2019},
  DOI = {10.18653/v1/N19-1423},
  PAGES = {4171--4186},
  TITLE = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
}

@INPROCEEDINGS{HerdadeKBS19,
  AUTHOR = {Herdade, Simao and Kappeler, Armin and Boakye, Kofi and Soares, Joao},
  URL = {http://papers.nips.cc/paper/9293-image-captioning-transforming-objects-into-words},
  YEAR = {2019},
  PAGES = {11135--11145},
  TITLE = {Image Captioning: Transforming Objects into Words},
}

@INPROCEEDINGS{huang1,
  AUTHOR = {Huang, Lun and Wang, Wenmin and Chen, Jie and Wei, Xiao-Yong},
  YEAR = {2019},
  DOI = {10.1109/ICCV.2019.00473},
  PAGES = {4633--4642},
  TITLE = {Attention on Attention for Image Captioning},
}

@INPROCEEDINGS{NIPS2017_3f5ee243,
  AUTHOR = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  EDITOR = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  PUBLISHER = {Curran Associates, Inc.},
  URL = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  BOOKTITLE = {Advances in Neural Information Processing Systems},
  YEAR = {2017},
  TITLE = {Attention is All you Need},
  VOLUME = {30},
}

@INPROCEEDINGS{spice,
  AUTHOR = {Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  EDITOR = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  LOCATION = {Cham},
  PUBLISHER = {Springer International Publishing},
  BOOKTITLE = {Computer Vision -- ECCV 2016},
  YEAR = {2016},
  ISBN = {978-3-319-46454-1},
  PAGES = {382--398},
  TITLE = {SPICE: Semantic Propositional Image Caption Evaluation},
}

@INPROCEEDINGS{meteor,
  AUTHOR = {Banerjee, Satanjeev and Lavie, Alon},
  LOCATION = {Ann Arbor, Michigan},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/W05-0909},
  BOOKTITLE = {Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization},
  YEAR = {2005},
  PAGES = {65--72},
  TITLE = {{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments},
}

@INPROCEEDINGS{lin-2004-rouge,
  AUTHOR = {Lin, Chin-Yew},
  LOCATION = {Barcelona, Spain},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/W04-1013},
  BOOKTITLE = {Text Summarization Branches Out},
  YEAR = {2004},
  PAGES = {74--81},
  TITLE = {{ROUGE}: A Package for Automatic Evaluation of Summaries},
}

@INPROCEEDINGS{cider,
  AUTHOR = {Vedantam, Ramakrishna and Zitnick, C. Lawrence and Parikh, Devi},
  BOOKTITLE = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  YEAR = {2015},
  DOI = {10.1109/CVPR.2015.7299087},
  PAGES = {4566--4575},
  TITLE = {CIDEr: Consensus-based image description evaluation},
}

@INPROCEEDINGS{papineni-etal-2002-bleu,
  AUTHOR = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  LOCATION = {Philadelphia, Pennsylvania, USA},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/P02-1040},
  BOOKTITLE = {Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics},
  YEAR = {2002},
  DOI = {10.3115/1073083.1073135},
  PAGES = {311--318},
  TITLE = {{B}leu: a Method for Automatic Evaluation of Machine Translation},
}

@INPROCEEDINGS{8578734,
  AUTHOR = {Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  BOOKTITLE = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  YEAR = {2018},
  DOI = {10.1109/CVPR.2018.00636},
  PAGES = {6077--6086},
  TITLE = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
}

@MISC{rfnet,
  AUTHOR = {Jiang, Wenhao and Ma, Lin and Jiang, Yu-Gang and Liu, Wei and Zhang, Tong},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1807.09986},
  DOI = {10.48550/ARXIV.1807.09986},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Recurrent Fusion Network for Image Captioning},
}

@INPROCEEDINGS{8099614,
  AUTHOR = {Rennie, Steven J. and Marcheret, Etienne and Mroueh, Youssef and Ross, Jerret and Goel, Vaibhava},
  BOOKTITLE = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  YEAR = {2017},
  DOI = {10.1109/CVPR.2017.131},
  PAGES = {1179--1195},
  TITLE = {Self-Critical Sequence Training for Image Captioning},
}

@INPROCEEDINGS{Yang_2019_CVPR,
  AUTHOR = {Yang, Xu and Tang, Kaihua and Zhang, Hanwang and Cai, Jianfei},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  YEAR = {2019},
  TITLE = {Auto-Encoding Scene Graphs for Image Captioning},
}

@MISC{GCN-LSTM,
  AUTHOR = {Yao, Ting and Pan, Yingwei and Li, Yehao and Mei, Tao},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1809.07041},
  YEAR = {2018},
  DOI = {10.48550/ARXIV.1809.07041},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Exploring Visual Relationship for Image Captioning},
}

@ARTICLE{galanter2016generative,
  AUTHOR = {Galanter, Philip},
  PUBLISHER = {John Wiley \& Sons Hoboken, NJ},
  YEAR = {2016},
  JOURNALTITLE = {A Companion to Digital Art},
  PAGES = {631},
  TITLE = {Generative art theory},
  VOLUME = {1},
}

@MISC{mordvintsev_2015,
  AUTHOR = {Mordvintsev, Alexander},
  PUBLISHER = {Google},
  URL = {https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html},
  YEAR = {2015},
  JOURNALTITLE = {Google AI Blog},
  TITLE = {Inceptionism: Going Deeper into Neural Networks},
}

@MISC{tensorflow2015,
  PUBLISHER = {tensorflow.org},
  URL = {https://www.tensorflow.org/tutorials/generative/deepdream},
  NOTE = {Google Colab available from tensorflow.org},
  TITLE = {DeepDream},
}

@MISC{StyleTransfer,
  AUTHOR = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1508.06576},
  YEAR = {2016},
  DOI = {10.48550/ARXIV.1508.06576},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Neural and Evolutionary Computing (cs.NE),Neurons and Cognition (q-bio.NC),FOS: Computer and information sciences,FOS: Computer and information sciences,FOS: Biological sciences,FOS: Biological sciences},
  TITLE = {A Neural Algorithm of Artistic Style},
}

@INPROCEEDINGS{NIPS2014_5ca3e9b1,
  AUTHOR = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  EDITOR = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K.Q.},
  PUBLISHER = {Curran Associates, Inc.},
  URL = {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
  BOOKTITLE = {Advances in Neural Information Processing Systems},
  YEAR = {2014},
  TITLE = {Generative Adversarial Nets},
  VOLUME = {27},
}

@INPROCEEDINGS{karras2019style,
  AUTHOR = {Karras, Tero and Laine, Samuli and Aila, Timo},
  BOOKTITLE = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  YEAR = {2019},
  PAGES = {4401--4410},
  TITLE = {A style-based generator architecture for generative adversarial networks},
}

@MISC{morris_2022,
  AUTHOR = {Morris, Jack},
  URL = {https://www.bibme.org/bibtex/website-citation},
  TITLE = {The Weird and Wonderful World of AI Art},
}

@INPROCEEDINGS{8477754,
  AUTHOR = {Soderlund, Jacob and Blair, Alan},
  BOOKTITLE = {2018 IEEE Congress on Evolutionary Computation (CEC)},
  YEAR = {2018},
  DOI = {10.1109/CEC.2018.8477754},
  PAGES = {1--8},
  TITLE = {Adversarial Image Generation Using Evolution and Deep Learning},
}

@ARTICLE{StyleGAN,
  AUTHOR = {Patashnik, Or and Wu, Zongze and Shechtman, Eli and Cohen{-}Or, Daniel and Lischinski, Dani},
  URL = {https://arxiv.org/abs/2103.17249},
  YEAR = {2021},
  EPRINT = {2103.17249},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery},
}

@ARTICLE{DiffusionModels,
  AUTHOR = {Dhariwal, Prafulla and Nichol, Alex},
  URL = {https://arxiv.org/abs/2105.05233},
  YEAR = {2021},
  EPRINT = {2105.05233},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Diffusion Models Beat GANs on Image Synthesis},
}

@MISC{ruDALLE,
  AUTHOR = {Shonenkov, Alex},
  URL = {https://github.com/ai-forever/ru-dalle},
  YEAR = {2021},
  TITLE = {ruDALL-E},
}

@MISC{DALLEmini,
  AUTHOR = {Boris, Dayma},
  URL = {https://huggingface.co/spaces/dalle-mini/dalle-mini},
  YEAR = {2022},
  TITLE = {DALL·E mini},
}

@MISC{DALLEpytorch,
  AUTHOR = {OpenAI},
  URL = {https://github.com/openai/DALL-E},
  YEAR = {2021},
  TITLE = {DALL-E},
}

@INPROCEEDINGS{liu2022design,
  AUTHOR = {Liu, Vivian and Chilton, Lydia B},
  BOOKTITLE = {CHI Conference on Human Factors in Computing Systems},
  PAGES = {1--23},
  TITLE = {Design Guidelines for Prompt Engineering Text-to-Image Generative Models},
}

@ARTICLE{LAION,
  AUTHOR = {Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  URL = {https://arxiv.org/abs/2111.02114},
  YEAR = {2021},
  EPRINT = {2111.02114},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {{LAION-400M:} Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs},
}

@MISC{WZRD,
  AUTHOR = {WZRD},
  URL = {https://wzrd.ai/},
  YEAR = {2020},
  TITLE = {WZRD},
}

@MISC{bias,
  AUTHOR = {Esser, Patrick and Rombach, Robin and Ommer, Björn},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2012.02516},
  YEAR = {2020},
  DOI = {10.48550/ARXIV.2012.02516},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {A Note on Data Biases in Generative Models},
}

@INPROCEEDINGS{Radford2019LanguageMA,
  AUTHOR = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  YEAR = {2019},
  TITLE = {Language Models are Unsupervised Multitask Learners},
}

@MISC{GPT3,
  AUTHOR = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2005.14165},
  YEAR = {2020},
  DOI = {10.48550/ARXIV.2005.14165},
  KEYWORDS = {Computation and Language (cs.CL),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Language Models are Few-Shot Learners},
}

@MISC{environment,
  AUTHOR = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1906.02243},
  YEAR = {2019},
  DOI = {10.48550/ARXIV.1906.02243},
  KEYWORDS = {Computation and Language (cs.CL),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Energy and Policy Considerations for Deep Learning in NLP},
}

@MISC{BERT,
  AUTHOR = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1810.04805},
  YEAR = {2018},
  DOI = {10.48550/ARXIV.1810.04805},
  KEYWORDS = {Computation and Language (cs.CL),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
}

@INPROCEEDINGS{attention,
  AUTHOR = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  EDITOR = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  PUBLISHER = {Curran Associates, Inc.},
  URL = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  BOOKTITLE = {Advances in Neural Information Processing Systems},
  YEAR = {2017},
  TITLE = {Attention is All you Need},
  VOLUME = {30},
}

@ARTICLE{3D,
  AUTHOR = {Mccormack, Jon and Gambardella, Camilo Cruz},
  YEAR = {2022},
  DOI = {10.1109/TEVC.2021.3095156},
  JOURNALTITLE = {IEEE Transactions on Evolutionary Computation},
  NUMBER = {1},
  PAGES = {88--99},
  TITLE = {Growing and Evolving 3-D Prints},
  VOLUME = {26},
}

@ARTICLE{misconduct,
  AUTHOR = {Dehouche, Nassim},
  YEAR = {2021},
  JOURNALTITLE = {Ethics in Science and Environmental Politics},
  PAGES = {17--23},
  TITLE = {Plagiarism in the age of massive Generative Pre-trained Transformers (GPT-3)},
  VOLUME = {21},
}

@INPROCEEDINGS{bias_ML,
  AUTHOR = {Srinivasan, Ramya and Uchino, Kanji},
  BOOKTITLE = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  YEAR = {2021},
  PAGES = {41--51},
  TITLE = {Biases in generative art: A causal look from the lens of art history},
}

@INPROCEEDINGS{qiao2022initial,
  AUTHOR = {Qiao, Han and Liu, Vivian and Chilton, Lydia},
  BOOKTITLE = {Creativity and Cognition},
  YEAR = {2022},
  PAGES = {15--28},
  TITLE = {Initial Images: Using Image Prompts to Improve Subject Representation in Multimodal AI Generated Art},
}

@MISC{unrealEngine,
  AUTHOR = {Aran, Komatsuzaki},
  PUBLISHER = {Twitter},
  URL = {https://twitter.com/arankomatsuzaki/status/1399471244760649729},
  YEAR = {2021},
  TITLE = {When you generate images with VQGAN CLIP, the image quality dramatically improves if you add "unreal engine" to your prompt. People are now calling this "unreal engine trick"},
}

@MISC{NFT,
  AUTHOR = {Wang, Qin and Li, Rujia and Wang, Qi and Chen, Shiping},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2105.07447},
  YEAR = {2021},
  DOI = {10.48550/ARXIV.2105.07447},
  KEYWORDS = {Cryptography and Security (cs.CR),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Non-Fungible Token (NFT): Overview, Evaluation, Opportunities and Challenges},
}

@ARTICLE{EfficientNet,
  AUTHOR = {Tan, Mingxing and Le, Quoc V.},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1905.11946},
  YEAR = {2019},
  DOI = {10.48550/ARXIV.1905.11946},
  KEYWORDS = {Machine Learning (cs.LG),Computer Vision and Pattern Recognition (cs.CV),Machine Learning (stat.ML),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
}

@MISC{SimCLR,
  AUTHOR = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2002.05709},
  YEAR = {2020},
  DOI = {10.48550/ARXIV.2002.05709},
  KEYWORDS = {Machine Learning (cs.LG),Computer Vision and Pattern Recognition (cs.CV),Machine Learning (stat.ML),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {A Simple Framework for Contrastive Learning of Visual Representations},
}

@MISC{BYOL,
  AUTHOR = {Grill, Jean-Bastien and Strub, Florian and Altché, Florent and Tallec, Corentin and Richemond, Pierre H. and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Kavukcuoglu, Koray and Munos, Rémi and Valko, Michal},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2006.07733},
  YEAR = {2020},
  DOI = {10.48550/ARXIV.2006.07733},
  KEYWORDS = {Machine Learning (cs.LG),Computer Vision and Pattern Recognition (cs.CV),Machine Learning (stat.ML),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Bootstrap your own latent: A new approach to self-supervised Learning},
}

@MISC{COCO,
  AUTHOR = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1405.0312},
  YEAR = {2014},
  DOI = {10.48550/ARXIV.1405.0312},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Microsoft COCO: Common Objects in Context},
}

@MISC{meshed_memory,
  AUTHOR = {Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1912.08226},
  YEAR = {2019},
  DOI = {10.48550/ARXIV.1912.08226},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Computation and Language (cs.CL),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Meshed-Memory Transformer for Image Captioning},
}

@ARTICLE{VAE,
  AUTHOR = {Kingma, Diederik P. and Welling, Max},
  URL = {http://arxiv.org/abs/1906.02691},
  YEAR = {2019},
  EPRINT = {1906.02691},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {An Introduction to Variational Autoencoders},
}

@MISC{DALLE,
  AUTHOR = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2102.12092},
  YEAR = {2021},
  DOI = {10.48550/ARXIV.2102.12092},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Zero-Shot Text-to-Image Generation},
}

@MISC{CLIP,
  AUTHOR = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2103.00020},
  YEAR = {2021},
  DOI = {10.48550/ARXIV.2103.00020},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Learning Transferable Visual Models From Natural Language Supervision},
}

@MISC{VilBert,
  AUTHOR = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1908.02265},
  YEAR = {2019},
  DOI = {10.48550/ARXIV.1908.02265},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Computation and Language (cs.CL),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},
}

@MISC{Flamingo,
  AUTHOR = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob and Borgeaud, Sebastian and Brock, Andrew and Nematzadeh, Aida and Sharifzadeh, Sahand and Binkowski, Mikolaj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Karen},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2204.14198},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2204.14198},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Artificial Intelligence (cs.AI),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Flamingo: a Visual Language Model for Few-Shot Learning},
}

@MISC{GAN,
  AUTHOR = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1406.2661},
  YEAR = {2014},
  DOI = {10.48550/ARXIV.1406.2661},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Generative Adversarial Networks},
}

@MISC{GLIDE,
  AUTHOR = {Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2112.10741},
  YEAR = {2021},
  DOI = {10.48550/ARXIV.2112.10741},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Graphics (cs.GR),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
}

@MISC{Pathways,
  AUTHOR = {Barham, Paul and Chowdhery, Aakanksha and Dean, Jeff and Ghemawat, Sanjay and Hand, Steven and Hurt, Dan and Isard, Michael and Lim, Hyeontaek and Pang, Ruoming and Roy, Sudip and Saeta, Brennan and Schuh, Parker and Sepassi, Ryan and Shafey, Laurent El and Thekkath, Chandramohan A. and Wu, Yonghui},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2203.12533},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2203.12533},
  KEYWORDS = {Distributed,Parallel,and Cluster Computing (cs.DC),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Pathways: Asynchronous Distributed Dataflow for ML},
}

@ARTICLE{explainaility,
  AUTHOR = {Joshi, Gargi and Walambe, Rahee and Kotecha, Ketan},
  YEAR = {2021},
  DOI = {10.1109/ACCESS.2021.3070212},
  JOURNALTITLE = {IEEE Access},
  PAGES = {59800--59821},
  TITLE = {A Review on Explainability in Multimodal Deep Neural Nets},
  VOLUME = {9},
}

@ARTICLE{ALIGN,
  AUTHOR = {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi{-}Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V. and Sung, Yun{-}Hsuan and Li, Zhen and Duerig, Tom},
  URL = {https://arxiv.org/abs/2102.05918},
  YEAR = {2021},
  EPRINT = {2102.05918},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision},
}

@ARTICLE{yuan2021florence,
  AUTHOR = {Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2111.11432},
  TITLE = {Florence: A New Foundation Model for Computer Vision},
}

@ARTICLE{agirre2009study,
  AUTHOR = {Agirre, Eneko and Alfonseca, Enrique and Hall, Keith and Kravalova, Jana and Pasca, Marius and Soroa, Aitor},
  YEAR = {2009},
  TITLE = {A study on similarity and relatedness using distributional and wordnet-based approaches},
}

@ARTICLE{ailem2018probabilistic,
  AUTHOR = {Ailem, Melissa and Zhang, Bowen and Bellet, Aurelien and Denis, Pascal and Sha, Fei},
  YEAR = {2018},
  TITLE = {A probabilistic model for joint learning of word embeddings from texts and images},
}

@INPROCEEDINGS{bosch2007image,
  AUTHOR = {Bosch, Anna and Zisserman, Andrew and Munoz, Xavier},
  ORGANIZATION = {Ieee},
  BOOKTITLE = {2007 IEEE 11th international conference on computer vision},
  YEAR = {2007},
  PAGES = {1--8},
  TITLE = {Image classification using random forests and ferns},
}

@ARTICLE{bruni2014multimodal,
  AUTHOR = {Bruni, Elia and Tran, Nam-Khanh and Baroni, Marco},
  YEAR = {2014},
  JOURNALTITLE = {Journal of artificial intelligence research},
  PAGES = {1--47},
  TITLE = {Multimodal distributional semantics},
  VOLUME = {49},
}

@ARTICLE{brysbaert2014concreteness,
  AUTHOR = {Brysbaert, Marc and Warriner, Amy Beth and Kuperman, Victor},
  PUBLISHER = {Springer},
  YEAR = {2014},
  JOURNALTITLE = {Behavior research methods},
  NUMBER = {3},
  PAGES = {904--911},
  TITLE = {Concreteness ratings for 40 thousand generally known English word lemmas},
  VOLUME = {46},
}

@INPROCEEDINGS{collell2017imagined,
  AUTHOR = {Collell, Guillem and Zhang, Ted and Moens, Marie-Francine},
  BOOKTITLE = {Proceedings of the AAAI Conference on Artificial Intelligence},
  YEAR = {2017},
  NUMBER = {1},
  TITLE = {Imagined visual representations as multimodal embeddings},
  VOLUME = {31},
}

@ARTICLE{devlin2018bert,
  AUTHOR = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  YEAR = {2018},
  JOURNALTITLE = {arXiv preprint arXiv:1810.04805},
  TITLE = {Bert: Pre-training of deep bidirectional transformers for language understanding},
}

@ARTICLE{devereux2014centre,
  AUTHOR = {Devereux, Barry J and Tyler, Lorraine K and Geertzen, Jeroen and Randall, Billi},
  PUBLISHER = {Springer},
  YEAR = {2014},
  JOURNALTITLE = {Behavior research methods},
  NUMBER = {4},
  PAGES = {1119--1127},
  TITLE = {The Centre for Speech, Language and the Brain (CSLB) concept property norms},
  VOLUME = {46},
}

@INPROCEEDINGS{esser2021taming,
  AUTHOR = {Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  BOOKTITLE = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  YEAR = {2021},
  PAGES = {12873--12883},
  TITLE = {Taming transformers for high-resolution image synthesis},
}

@ARTICLE{harnad1990symbol,
  AUTHOR = {Harnad, Stevan},
  PUBLISHER = {Elsevier},
  YEAR = {1990},
  JOURNALTITLE = {Physica D: Nonlinear Phenomena},
  NUMBER = {1-3},
  PAGES = {335--346},
  TITLE = {The symbol grounding problem},
  VOLUME = {42},
}

@ARTICLE{harris1954distributional,
  AUTHOR = {Harris, Z and others},
  YEAR = {1954},
  JOURNALTITLE = {Word World},
  NUMBER = {23},
  PAGES = {146--162},
  TITLE = {Distributional hypothesis},
  VOLUME = {10},
}

@INPROCEEDINGS{hill2014learning,
  AUTHOR = {Hill, Felix and Korhonen, Anna},
  BOOKTITLE = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  YEAR = {2014},
  PAGES = {255--265},
  TITLE = {Learning abstract concept embeddings from multi-modal data: Since you probably can’t see what I mean},
}

@ARTICLE{hill2015simlex,
  AUTHOR = {Hill, Felix and Reichart, Roi and Korhonen, Anna},
  PUBLISHER = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…},
  YEAR = {2015},
  JOURNALTITLE = {Computational Linguistics},
  NUMBER = {4},
  PAGES = {665--695},
  TITLE = {Simlex-999: Evaluating semantic models with (genuine) similarity estimation},
  VOLUME = {41},
}

@ARTICLE{hochreiter1997long,
  AUTHOR = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  PUBLISHER = {MIT Press},
  YEAR = {1997},
  JOURNALTITLE = {Neural computation},
  NUMBER = {8},
  PAGES = {1735--1780},
  TITLE = {Long short-term memory},
  VOLUME = {9},
}

@INPROCEEDINGS{hu2021unit,
  AUTHOR = {Hu, Ronghang and Singh, Amanpreet},
  BOOKTITLE = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  YEAR = {2021},
  PAGES = {1439--1449},
  TITLE = {Unit: Multimodal multitask learning with a unified transformer},
}

@ARTICLE{ive2019distilling,
  AUTHOR = {Ive, Julia and Madhyastha, Pranava and Specia, Lucia},
  YEAR = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1906.07701},
  TITLE = {Distilling translations with visual awareness},
}

@INPROCEEDINGS{kiela2014learning,
  AUTHOR = {Kiela, Douwe and Bottou, Léon},
  BOOKTITLE = {Proceedings of the 2014 Conference on empirical methods in natural language processing (EMNLP)},
  YEAR = {2014},
  PAGES = {36--45},
  TITLE = {Learning image embeddings using convolutional neural networks for improved multi-modal semantics},
}

@ARTICLE{kiela2017learning,
  AUTHOR = {Kiela, Douwe and Conneau, Alexis and Jabri, Allan and Nickel, Maximilian},
  YEAR = {2017},
  JOURNALTITLE = {arXiv preprint arXiv:1707.06320},
  TITLE = {Learning visually grounded sentence representations},
}

@INPROCEEDINGS{kiros2018illustrative,
  AUTHOR = {Kiros, Jamie and Chan, William and Hinton, Geoffrey},
  BOOKTITLE = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  YEAR = {2018},
  PAGES = {922--933},
  TITLE = {Illustrative language understanding: Large-scale visual grounding with image search},
}

@INPROCEEDINGS{kottur2016visual,
  AUTHOR = {Kottur, Satwik and Vedantam, Ramakrishna and Moura, José MF and Parikh, Devi},
  BOOKTITLE = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  YEAR = {2016},
  PAGES = {4985--4994},
  TITLE = {Visual word2vec (vis-w2v): Learning visually grounded word embeddings using abstract scenes},
}

@ARTICLE{krizhevsky2012imagenet,
  AUTHOR = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  YEAR = {2012},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Imagenet classification with deep convolutional neural networks},
  VOLUME = {25},
}

@ARTICLE{lazaridou2015combining,
  AUTHOR = {Lazaridou, Angeliki and Pham, Nghia The and Baroni, Marco},
  YEAR = {2015},
  JOURNALTITLE = {arXiv preprint arXiv:1501.02598},
  TITLE = {Combining language and vision with a multimodal skip-gram model},
}

@INPROCEEDINGS{lin2014microsoft,
  AUTHOR = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C Lawrence},
  ORGANIZATION = {Springer},
  BOOKTITLE = {European conference on computer vision},
  YEAR = {2014},
  PAGES = {740--755},
  TITLE = {Microsoft coco: Common objects in context},
}

@ARTICLE{lu2022imagination,
  AUTHOR = {Lu, Yujie and Zhu, Wanrong and Wang, Xin Eric and Eckstein, Miguel and Wang, William Yang},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2204.08535},
  TITLE = {Imagination-Augmented Natural Language Understanding},
}

@ARTICLE{yu2022coca,
  AUTHOR = {Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2205.01917},
  TITLE = {CoCa: Contrastive Captioners are Image-Text Foundation Models},
}

@ARTICLE{Mikolov2013,
  AUTHOR = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  YEAR = {2013},
  JOURNALTITLE = {arXiv preprint arXiv:1301.3781},
  TITLE = {Efficient estimation of word representations in vector space},
}

@ARTICLE{mikolov2013efficient,
  AUTHOR = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  YEAR = {2013},
  JOURNALTITLE = {arXiv preprint arXiv:1301.3781},
  TITLE = {Efficient estimation of word representations in vector space},
}

@ARTICLE{Mikolov2013a,
  AUTHOR = {Mikolov, Tomas and Le, Quoc V. and Sutskever, Ilya},
  YEAR = {2013},
  EPRINT = {1309.4168},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1309.4168v1:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Exploiting Similarities among Languages for Machine Translation},
}

@ARTICLE{Mikolov2013b,
  AUTHOR = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  YEAR = {2013},
  EPRINT = {1310.4546},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1310.4546v1:PDF},
  KEYWORDS = {cs.CL,cs.LG,stat.ML},
  TITLE = {Distributed Representations of Words and Phrases and their Compositionality},
}

@ARTICLE{Bojanowski2016,
  AUTHOR = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  YEAR = {2016},
  EPRINT = {1607.04606},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1607.04606v2:PDF},
  KEYWORDS = {cs.CL,cs.LG},
  TITLE = {Enriching Word Vectors with Subword Information},
}

@ARTICLE{Bahdanau2014,
  AUTHOR = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  YEAR = {2014},
  EPRINT = {1409.0473},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1409.0473v7:PDF},
  KEYWORDS = {cs.CL,cs.LG,cs.NE,stat.ML},
  TITLE = {Neural Machine Translation by Jointly Learning to Align and Translate},
}

@ARTICLE{Sutskever2014,
  AUTHOR = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  YEAR = {2014},
  EPRINT = {1409.3215},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1409.3215v3:PDF},
  KEYWORDS = {cs.CL,cs.LG},
  TITLE = {Sequence to Sequence Learning with Neural Networks},
}

@ARTICLE{Raffel2019,
  AUTHOR = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  YEAR = {2019},
  EPRINT = {1910.10683},
  EPRINTCLASS = {cs.LG},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1910.10683v3:PDF},
  KEYWORDS = {cs.LG,cs.CL,stat.ML},
  TITLE = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
}

@BOOK{Pilehvar2021,
  AUTHOR = {Pilehvar, Mohammad Taher and Camacho-Collados, Jose},
  PUBLISHER = {Springer International Publishing},
  YEAR = {2021},
  DOI = {10.1007/978-3-031-02177-0},
  TITLE = {Embeddings in Natural Language Processing},
}

@ARTICLE{Cho2014,
  AUTHOR = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  YEAR = {2014},
  EPRINT = {1406.1078},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1406.1078v3:PDF},
  KEYWORDS = {cs.CL,cs.LG,cs.NE,stat.ML},
  TITLE = {Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation},
}

@ARTICLE{luong17,
  AUTHOR = {Luong, Minh{-}Thang and Brevdo, Eugene and Zhao, Rui},
  YEAR = {2017},
  NOTE = {https://github.com/tensorflow/nmt},
  TITLE = {Neural Machine Translation (seq2seq) Tutorial},
}

@ARTICLE{Manning2022,
  AUTHOR = {Manning, Chris and Goldie, Anna and Hewitt, John},
  YEAR = {2022},
  NOTE = {https://web.stanford.edu/class/cs224n/slides/},
  TITLE = {Stanford CS224n: Natural Language Processing with Deep Learning},
}

@ARTICLE{Google2022,
  AUTHOR = {Google},
  YEAR = {2022},
  NOTE = {https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space},
  TITLE = {Embeddings: Translating to a Lower-Dimensional Space},
}

@ARTICLE{Jumper2021,
  AUTHOR = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žı́dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
  PUBLISHER = {Springer Science and Business Media {LLC}},
  YEAR = {2021},
  DOI = {10.1038/s41586-021-03819-2},
  JOURNALTITLE = {Nature},
  NUMBER = {7873},
  PAGES = {583--589},
  TITLE = {Highly accurate protein structure prediction with {AlphaFold}},
  VOLUME = {596},
}

@ARTICLE{Zhou2020,
  AUTHOR = {Zhou, Yanqi and Roy, Sudip and Abdolrashidi, Amirali and Wong, Daniel and Ma, Peter and Xu, Qiumin and Liu, Hanxiao and Phothilimthana, Phitchaya Mangpo and Wang, Shen and Goldie, Anna and Mirhoseini, Azalia and Laudon, James},
  YEAR = {2020},
  EPRINT = {2010.12438},
  EPRINTCLASS = {cs.LG},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2010.12438v2:PDF},
  JOURNALTITLE = {NeurIPS 2020},
  KEYWORDS = {cs.LG,cs.DC},
  TITLE = {Transferable Graph Optimizers for ML Compilers},
}

@ARTICLE{Sejnowski2020,
  AUTHOR = {Sejnowski, Terrence J.},
  YEAR = {2020},
  DOI = {10.1073/pnas.1907373117},
  EPRINT = {2002.04806},
  EPRINTCLASS = {q-bio.NC},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2002.04806v1:PDF},
  JOURNALTITLE = {Proceedings of the National Academy of Sciences U.S.A. (2020) https://www.pnas.org/content/early/2020/01/23/1907373117},
  KEYWORDS = {q-bio.NC,cs.AI,cs.LG,cs.NE},
  TITLE = {The Unreasonable Effectiveness of Deep Learning in Artificial Intelligence},
}

@ARTICLE{Saifee2020,
  AUTHOR = {Saifee, Moiz},
  YEAR = {2020},
  NOTE = {https://towardsdatascience.com/gpt-3-the-new-mighty-language-model-from-openai-a74ff35346fc},
  TITLE = {GPT-3: The New Mighty Language Model from OpenAI},
}

@ARTICLE{Radford2018,
  AUTHOR = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  YEAR = {2018},
  KEYWORDS = {final thema:transformer},
  TITLE = {Improving language understanding by generative pre-training},
}

@ARTICLE{Hart1995,
  AUTHOR = {Hart, B. and Risley, T. R.},
  YEAR = {1995},
  JOURNALTITLE = {Baltimore, MD: Paul H. Brookes Publishing Company,},
  TITLE = {Meaningful differences in the everyday experience of young American children},
}

@INPROCEEDINGS{Bender2021,
  AUTHOR = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  LOCATION = {Virtual Event, Canada},
  PUBLISHER = {Association for Computing Machinery},
  URL = {https://doi.org/10.1145/3442188.3445922},
  BOOKTITLE = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  YEAR = {2021},
  DOI = {10.1145/3442188.3445922},
  ISBN = {9781450383097},
  PAGES = {610--623},
  SERIES = {FAccT '21},
  TITLE = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
}

@ARTICLE{Rogers2020,
  AUTHOR = {Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
  YEAR = {2020},
  EPRINT = {2002.12327},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2002.12327v3:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {A Primer in BERTology: What we know about how BERT works},
}

@ARTICLE{Clark2019,
  AUTHOR = {Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D.},
  YEAR = {2019},
  EPRINT = {1906.04341},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1906.04341v1:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {What Does BERT Look At? An Analysis of BERT's Attention},
}

@ARTICLE{Lialin2022,
  AUTHOR = {Lialin, Vladislav and Zhao, Kevin and Shivagunde, Namrata and Rumshisky, Anna},
  YEAR = {2022},
  EPRINT = {2205.10696},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2205.10696v1:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Life after BERT: What do Other Muppets Understand about Language?},
}

@ARTICLE{Narang2021,
  AUTHOR = {Narang, Sharan and Chung, Hyung Won and Tay, Yi and Fedus, William and Fevry, Thibault and Matena, Michael and Malkan, Karishma and Fiedel, Noah and Shazeer, Noam and Lan, Zhenzhong and Zhou, Yanqi and Li, Wei and Ding, Nan and Marcus, Jake and Roberts, Adam and Raffel, Colin},
  YEAR = {2021},
  EPRINT = {2102.11972},
  EPRINTCLASS = {cs.LG},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2102.11972v2:PDF},
  KEYWORDS = {cs.LG,cs.CL},
  TITLE = {Do Transformer Modifications Transfer Across Implementations and Applications?},
}

@ARTICLE{Ritchie2020,
  AUTHOR = {Ritchie, Hannah and Roser, Max and Rosado, Pablo},
  YEAR = {2020},
  JOURNALTITLE = {Our World in Data},
  NOTE = {https://ourworldindata.org/co2-and-other-greenhouse-gas-emissions},
  TITLE = {$CO_2$ and Greenhouse Gas Emissions},
}

@INPROCEEDINGS{Lin2019,
  AUTHOR = {Lin, Yongjie and Tan, Yi Chern and Frank, Robert},
  PUBLISHER = {Association for Computational Linguistics},
  BOOKTITLE = {Proceedings of the 2019 {ACL} Workshop {BlackboxNLP}: Analyzing and Interpreting Neural Networks for {NLP}},
  YEAR = {2019},
  DOI = {10.18653/v1/w19-4825},
  TITLE = {Open Sesame: Getting inside {BERT}'s Linguistic Knowledge},
}

@ARTICLE{Ettinger2019,
  AUTHOR = {Ettinger, Allyson},
  YEAR = {2019},
  EPRINT = {1907.13528},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1907.13528v2:PDF},
  KEYWORDS = {cs.CL,cs.AI},
  TITLE = {What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models},
}

@ARTICLE{Forbes2019,
  AUTHOR = {Forbes, Maxwell and Holtzman, Ari and Choi, Yejin},
  YEAR = {2019},
  EPRINT = {1908.02899},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1908.02899v1:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Do Neural Language Representations Learn Physical Commonsense?},
}

@ARTICLE{Voita2019,
  AUTHOR = {Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
  YEAR = {2019},
  EPRINT = {1905.09418},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1905.09418v2:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned},
}

@ARTICLE{Liu2019,
  AUTHOR = {Liu, Nelson F. and Gardner, Matt and Belinkov, Yonatan and Peters, Matthew E. and Smith, Noah A.},
  YEAR = {2019},
  EPRINT = {1903.08855},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1903.08855v5:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Linguistic Knowledge and Transferability of Contextual Representations},
}

@ARTICLE{Da2019,
  AUTHOR = {Da, Jeff and Kasai, Jungo},
  YEAR = {2019},
  EPRINT = {1910.01157},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1910.01157v2:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Cracking the Contextual Commonsense Code: Understanding Commonsense Reasoning Aptitude of Deep Contextual Representations},
}

@INPROCEEDINGS{pennington2014glove,
  AUTHOR = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  BOOKTITLE = {Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  YEAR = {2014},
  PAGES = {1532--1543},
  TITLE = {Glove: Global vectors for word representation},
}

@ARTICLE{pezzelle2021word,
  AUTHOR = {Pezzelle, Sandro and Takmaz, Ece and Fernández, Raquel},
  PUBLISHER = {MIT Press},
  YEAR = {2021},
  JOURNALTITLE = {Transactions of the Association for Computational Linguistics},
  PAGES = {1563--1579},
  TITLE = {Word representation learning in multimodal pre-trained transformers: An intrinsic evaluation},
  VOLUME = {9},
}

@ARTICLE{russakovsky2015imagenet,
  AUTHOR = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  PUBLISHER = {Springer},
  YEAR = {2015},
  JOURNALTITLE = {International journal of computer vision},
  NUMBER = {3},
  PAGES = {211--252},
  TITLE = {Imagenet large scale visual recognition challenge},
  VOLUME = {115},
}

@INPROCEEDINGS{singh2022flava,
  AUTHOR = {Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  YEAR = {2022},
  PAGES = {15638--15650},
  TITLE = {Flava: A foundational language and vision alignment model},
}

@INPROCEEDINGS{silberer2014learning,
  AUTHOR = {Silberer, Carina and Lapata, Mirella},
  BOOKTITLE = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  YEAR = {2014},
  PAGES = {721--732},
  TITLE = {Learning grounded meaning representations with autoencoders},
}

@ARTICLE{sun2021multimodal,
  AUTHOR = {Sun, Qingfeng and Wang, Yujing and Xu, Can and Zheng, Kai and Yang, Yaming and Hu, Huang and Xu, Fei and Zhang, Jessica and Geng, Xiubo and Jiang, Daxin},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2110.08515},
  TITLE = {Multimodal dialogue response generation},
}

@ARTICLE{tan2020vokenization,
  AUTHOR = {Tan, Hao and Bansal, Mohit},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2010.06775},
  TITLE = {Vokenization: Improving language understanding with contextualized, visual-grounded supervision},
}

@ARTICLE{wang2018glue,
  AUTHOR = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  YEAR = {2018},
  JOURNALTITLE = {arXiv preprint arXiv:1804.07461},
  TITLE = {GLUE: A multi-task benchmark and analysis platform for natural language understanding},
}

@ARTICLE{zellers2018swag,
  AUTHOR = {Zellers, Rowan and Bisk, Yonatan and Schwartz, Roy and Choi, Yejin},
  YEAR = {2018},
  JOURNALTITLE = {arXiv preprint arXiv:1808.05326},
  TITLE = {Swag: A large-scale adversarial dataset for grounded commonsense inference},
}

@MANUAL{rlang,
  AUTHOR = {{R Core Team}},
  LOCATION = {Vienna, Austria},
  ORGANIZATION = {R Foundation for Statistical Computing},
  URL = {https://www.R-project.org/},
  YEAR = {2018},
  TITLE = {R: A Language and Environment for Statistical Computing},
}

@INPROCEEDINGS{radford2021learning,
  AUTHOR = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  ORGANIZATION = {PMLR},
  BOOKTITLE = {International Conference on Machine Learning},
  YEAR = {2021},
  PAGES = {8748--8763},
  TITLE = {Learning transferable visual models from natural language supervision},
}

@ARTICLE{baevski2022data2vec,
  AUTHOR = {Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2202.03555},
  TITLE = {Data2vec: A general framework for self-supervised learning in speech, vision and language},
}

@ARTICLE{bao2021beit,
  AUTHOR = {Bao, Hangbo and Dong, Li and Wei, Furu},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2106.08254},
  TITLE = {Beit: Bert pre-training of image transformers},
}

@ARTICLE{radford2019language,
  AUTHOR = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  YEAR = {2019},
  JOURNALTITLE = {OpenAI blog},
  NUMBER = {8},
  PAGES = {9},
  TITLE = {Language models are unsupervised multitask learners},
  VOLUME = {1},
}

@ARTICLE{shen2021much,
  AUTHOR = {Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2107.06383},
  TITLE = {How Much Can CLIP Benefit Vision-and-Language Tasks?},
}

@INPROCEEDINGS{silberer2012grounded,
  AUTHOR = {Silberer, Carina and Lapata, Mirella},
  ORGANIZATION = {ACL (Association for Computational Linguistics)},
  BOOKTITLE = {Tsujii J, Henderson J, Paşca M, editors. Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning; 2012 Jul 12--14; Jeju Island, Korea. Stroudsburg: ACL; 2012. p. 1423-33.},
  YEAR = {2012},
  TITLE = {Grounded models of semantic representation},
}

@ARTICLE{sennrich2015neural,
  AUTHOR = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  YEAR = {2015},
  JOURNALTITLE = {arXiv preprint arXiv:1508.07909},
  TITLE = {Neural machine translation of rare words with subword units},
}

@ARTICLE{baevski2020wav2vec,
  AUTHOR = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  YEAR = {2020},
  JOURNALTITLE = {Advances in Neural Information Processing Systems},
  PAGES = {12449--12460},
  TITLE = {wav2vec 2.0: A framework for self-supervised learning of speech representations},
  VOLUME = {33},
}

@INPROCEEDINGS{chen2021empirical,
  AUTHOR = {Chen, Xinlei and Xie, Saining and He, Kaiming},
  BOOKTITLE = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  YEAR = {2021},
  PAGES = {9640--9649},
  TITLE = {An empirical study of training self-supervised vision transformers},
}

@INPROCEEDINGS{he2022masked,
  AUTHOR = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Dollár, Piotr and Girshick, Ross},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  YEAR = {2022},
  PAGES = {16000--16009},
  TITLE = {Masked autoencoders are scalable vision learners},
}

@ARTICLE{zhang2020contrastive,
  AUTHOR = {Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2010.00747},
  TITLE = {Contrastive learning of medical visual representations from paired images and text},
}

@ONLINE{sutton2019bitterlesson,
  AUTHOR = {Sutton, R. S.},
  URL = {http://www.incompleteideas.net/IncIdeas/BitterLesson.html},
  YEAR = {2019},
  TITLE = {The Bitter Lesson},
}

@ONLINE{openai2021clipblog,
  AUTHOR = {OpenAI},
  URL = {https://openai.com/blog/clip/},
  TITLE = {CLIP: Connection Text and Images},
}

@ONLINE{alford2021alignparams,
  AUTHOR = {Alford, A.},
  URL = {https://www.infoq.com/news/2021/07/google-vision-language-ai/},
  YEAR = {2021},
  TITLE = {Google Announces 800M Parameter Vision-Language AI Model ALIGN},
}

@ONLINE{schuhmann2022laion,
  AUTHOR = {Schuhmann, C.},
  URL = {https://laion.ai/blog/laion-400-open-dataset/},
  YEAR = {2022},
  TITLE = {Laion-400-Million Open Dataset},
}

@ONLINE{solawetz2021florenceopen,
  AUTHOR = {Solawetz, J.},
  URL = {https://blog.roboflow.com/florence-a-new-foundational-model-for-computer-vision/},
  TITLE = {Florence: A New Foundation for Computer Vision},
}

@INPROCEEDINGS{wei2022masked,
  AUTHOR = {Wei, Chen and Fan, Haoqi and Xie, Saining and Wu, Chao-Yuan and Yuille, Alan and Feichtenhofer, Christoph},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  YEAR = {2022},
  PAGES = {14668--14678},
  TITLE = {Masked feature prediction for self-supervised visual pre-training},
}

@INPROCEEDINGS{jaegle2021perceiver,
  AUTHOR = {Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  ORGANIZATION = {PMLR},
  BOOKTITLE = {International conference on machine learning},
  YEAR = {2021},
  PAGES = {4651--4664},
  TITLE = {Perceiver: General perception with iterative attention},
}

@ARTICLE{alayrac2022flamingo,
  AUTHOR = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2204.14198},
  TITLE = {Flamingo: a visual language model for few-shot learning},
}

@ARTICLE{lu2019vilbert,
  AUTHOR = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  YEAR = {2019},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  VOLUME = {32},
}

@ARTICLE{uppal2022multimodal,
  AUTHOR = {Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumder, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir},
  PUBLISHER = {Elsevier},
  YEAR = {2022},
  JOURNALTITLE = {Information Fusion},
  PAGES = {149--171},
  TITLE = {Multimodal research in vision and language: A review of current and emerging trends},
  VOLUME = {77},
}

@ARTICLE{hoffmann2022training,
  AUTHOR = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2203.15556},
  TITLE = {Training Compute-Optimal Large Language Models},
}

@INPROCEEDINGS{jia2021scaling,
  AUTHOR = {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  ORGANIZATION = {PMLR},
  BOOKTITLE = {International Conference on Machine Learning},
  YEAR = {2021},
  PAGES = {4904--4916},
  TITLE = {Scaling up visual and vision-language representation learning with noisy text supervision},
}

@ARTICLE{perez2021true,
  AUTHOR = {Perez, Ethan and Kiela, Douwe and Cho, Kyunghyun},
  YEAR = {2021},
  JOURNALTITLE = {Advances in Neural Information Processing Systems},
  PAGES = {11054--11070},
  TITLE = {True few-shot learning with language models},
  VOLUME = {34},
}

@ARTICLE{zeng2022socratic,
  AUTHOR = {Zeng, Andy and Wong, Adrian and Welker, Stefan and Choromanski, Krzysztof and Tombari, Federico and Purohit, Aveek and Ryoo, Michael and Sindhwani, Vikas and Lee, Johnny and Vanhoucke, Vincent and others},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2204.00598},
  TITLE = {Socratic models: Composing zero-shot multimodal reasoning with language},
}

@ARTICLE{ren2015faster,
  AUTHOR = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  YEAR = {2015},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Faster r-cnn: Towards real-time object detection with region proposal networks},
  VOLUME = {28},
}

@INPROCEEDINGS{krishnavisualgenome,
  AUTHOR = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and Bernstein, Michael and Fei-Fei, Li},
  URL = {https://arxiv.org/abs/1602.07332},
  YEAR = {2016},
  TITLE = {Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
}

@ARTICLE{sikarwar2022efficacy,
  AUTHOR = {Sikarwar, Ankur and Kreiman, Gabriel},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2201.03965},
  TITLE = {On the efficacy of co-attention transformer layers in visual question answering},
}

@ARTICLE{chowdhery2022palm,
  AUTHOR = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2204.02311},
  TITLE = {Palm: Scaling language modeling with pathways},
}

@ARTICLE{das2017human,
  AUTHOR = {Das, Abhishek and Agrawal, Harsh and Zitnick, Larry and Parikh, Devi and Batra, Dhruv},
  PUBLISHER = {Elsevier},
  YEAR = {2017},
  JOURNALTITLE = {Computer Vision and Image Understanding},
  PAGES = {90--100},
  TITLE = {Human attention in visual question answering: Do humans and deep networks look at the same regions?},
  VOLUME = {163},
}

@ARTICLE{HuangFusion2020,
  AUTHOR = {Huang, Shih-Cheng and Pareek, Anuj and Seyyedi, Saeed and Banerjee, Imon and Lungren, Matthew P},
  PUBLISHER = {Nature Publishing Group},
  YEAR = {2020},
  JOURNALTITLE = {NPJ digital medicine},
  NUMBER = {1},
  PAGES = {1--9},
  TITLE = {Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines},
  VOLUME = {3},
}

@ARTICLE{Katzman2018,
  AUTHOR = {Katzman, Jared L and Shaham, Uri and Cloninger, Alexander and Bates, Jonathan and Jiang, Tingting and Kluger, Yuval},
  PUBLISHER = {BioMed Central},
  YEAR = {2018},
  JOURNALTITLE = {BMC medical research methodology},
  NUMBER = {1},
  PAGES = {1--12},
  TITLE = {DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network},
  VOLUME = {18},
}

@INPROCEEDINGS{DeepConvSurv,
  AUTHOR = {Zhu, Xinliang and Yao, Jiawen and Huang, Junzhou},
  ORGANIZATION = {IEEE},
  BOOKTITLE = {2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  YEAR = {2016},
  PAGES = {544--547},
  TITLE = {Deep convolutional neural network for survival analysis with pathological images},
}

@ARTICLE{TongAE,
  AUTHOR = {Tong, Chao and Li, Jun and Lang, Chao and Kong, Fanxin and Niu, Jianwei and Rodrigues, Joel JPC},
  PUBLISHER = {Elsevier},
  YEAR = {2018},
  JOURNALTITLE = {Journal of parallel and distributed computing},
  PAGES = {267--273},
  TITLE = {An efficient deep model for day-ahead electricity load forecasting with stacked denoising auto-encoders},
  VOLUME = {117},
}

@ARTICLE{carreira2022hierarchical,
  AUTHOR = {Carreira, Joao and Koppula, Skanda and Zoran, Daniel and Recasens, Adria and Ionescu, Catalin and Henaff, Olivier and Shelhamer, Evan and Arandjelovic, Relja and Botvinick, Matt and Vinyals, Oriol and Simonyan, Karen and Zisserman, Andrew and Jaegle, Andrew},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2202.10890},
  TITLE = {Hierarchical Perceiver},
}

@INPROCEEDINGS{DBLP:conf/icml/JaegleGBVZC21,
  AUTHOR = {Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, João},
  EDITOR = {Meila, Marina and Zhang, Tong},
  PUBLISHER = {PMLR},
  URL = {http://proceedings.mlr.press/v139/jaegle21a.html},
  BOOKTITLE = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  YEAR = {2021},
  PAGES = {4651--4664},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {Perceiver: General Perception with Iterative Attention},
  VOLUME = {139},
}

@ARTICLE{lecun2022path,
  AUTHOR = {LeCun, Yann},
  YEAR = {2022},
  TITLE = {A Path Towards Autonomous Machine Intelligence Version 0.9. 2, 2022-06-27},
}

@ARTICLE{bachmann2022multimae,
  AUTHOR = {Bachmann, Roman and Mizrahi, David and Atanov, Andrei and Zamir, Amir},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2204.01678},
  TITLE = {MultiMAE: Multi-modal Multi-task Masked Autoencoders},
}

@INPROCEEDINGS{DBLP:conf/nips/AkbariYQCCCG21,
  AUTHOR = {Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei{-}Hong and Chang, Shih{-}Fu and Cui, Yin and Gong, Boqing},
  EDITOR = {Ranzato, Marc'Aurelio and Beygelzimer, Alina and Dauphin, Yann N. and Liang, Percy and Vaughan, Jennifer Wortman},
  URL = {https://proceedings.neurips.cc/paper/2021/hash/cb3213ada48302953cb0f166464ab356-Abstract.html},
  BOOKTITLE = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual},
  YEAR = {2021},
  PAGES = {24206--24221},
  TITLE = {{VATT:} Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text},
}

@ARTICLE{DBLP:journals/jstsp/ZhangYHD20,
  AUTHOR = {Zhang, Chao and Yang, Zichao and He, Xiaodong and Deng, Li},
  URL = {https://doi.org/10.1109/JSTSP.2020.2987728},
  YEAR = {2020},
  DOI = {10.1109/JSTSP.2020.2987728},
  JOURNALTITLE = {{IEEE} J. Sel. Top. Signal Process.},
  NUMBER = {3},
  PAGES = {478--493},
  TITLE = {Multimodal Intelligence: Representation Learning, Information Fusion, and Applications},
  VOLUME = {14},
}

@ARTICLE{iv2021multimodal,
  AUTHOR = {IV, William C. Sleeman and Kapoor, Rishabh and Ghosh, Preetam},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2109.09020},
  TITLE = {Multimodal Classification: Current Landscape, Taxonomy and Future Directions},
}

@ARTICLE{baltrušaitis2017multimodal,
  AUTHOR = {Baltrušaitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  YEAR = {2017},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-1705.09406},
  TITLE = {Multimodal Machine Learning: A Survey and Taxonomy},
}

@ARTICLE{DBLP:journals/pami/BengioCV13,
  AUTHOR = {Bengio, Yoshua and Courville, Aaron C. and Vincent, Pascal},
  URL = {https://doi.org/10.1109/TPAMI.2013.50},
  YEAR = {2013},
  DOI = {10.1109/TPAMI.2013.50},
  JOURNALTITLE = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  NUMBER = {8},
  PAGES = {1798--1828},
  TITLE = {Representation Learning: {A} Review and New Perspectives},
  VOLUME = {35},
}

@ARTICLE{wu2022nuwainfinity,
  AUTHOR = {Wu, Chenfei and Liang, Jian and Hu, Xiaowei and Gan, Zhe and Wang, Jianfeng and Wang, Lijuan and Liu, Zicheng and Fang, Yuejian and Duan, Nan},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2207.09814},
  TITLE = {NUWA-Infinity: Autoregressive over Autoregressive Generation for Infinite Visual Synthesis},
}

@ARTICLE{wu2021nwa,
  AUTHOR = {Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2111.12417},
  TITLE = {NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion},
}

@INPROCEEDINGS{Zhu_2022_CVPR,
  AUTHOR = {Zhu, Xizhou and Zhu, Jinguo and Li, Hao and Wu, Xiaoshi and Li, Hongsheng and Wang, Xiaohua and Dai, Jifeng},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  YEAR = {2022},
  PAGES = {16804--16815},
  TITLE = {Uni-Perceiver: Pre-Training Unified Architecture for Generic Perception for Zero-Shot and Few-Shot Tasks},
}

@ARTICLE{likhosherstov2021polyvit,
  AUTHOR = {Likhosherstov, Valerii and Arnab, Anurag and Choromanski, Krzysztof and Lucic, Mario and Tay, Yi and Weller, Adrian and Dehghani, Mostafa},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2111.12993},
  TITLE = {PolyViT: Co-training Vision Transformers on Images, Videos and Audio},
}

@INPROCEEDINGS{DBLP:conf/aaai/ZhangZ0CAP22,
  AUTHOR = {Zhang, Zizhao and Zhang, Han and Zhao, Long and Chen, Ting and Arik, Sercan Ö. and Pfister, Tomas},
  PUBLISHER = {{AAAI} Press},
  URL = {https://ojs.aaai.org/index.php/AAAI/article/view/20252},
  BOOKTITLE = {Thirty-Sixth {AAAI} Conference on Artificial Intelligence, {AAAI} 2022, Thirty-Fourth Conference on Innovative Applications of Artificial Intelligence, {IAAI} 2022, The Twelveth Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2022 Virtual Event, February 22 - March 1, 2022},
  YEAR = {2022},
  PAGES = {3417--3425},
  TITLE = {Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding},
}

@ARTICLE{wang2021multimodal,
  AUTHOR = {Wang, Luyu and Luc, Pauline and Recasens, Adria and Alayrac, Jean-Baptiste and van den Oord, Aaron},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2104.12807},
  TITLE = {Multimodal Self-Supervised Learning of General Audio Representations},
}

@INPROCEEDINGS{Zhang_2019_CVPR,
  AUTHOR = {Zhang, Wenxiao and Xiao, Chunxia},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  YEAR = {2019},
  TITLE = {PCAN: 3D Attention Map Learning Using Contextual Information for Point Cloud Based Retrieval},
}

@ARTICLE{kahatapitiya2021swat,
  AUTHOR = {Kahatapitiya, Kumara and Ryoo, Michael S.},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2111.13677},
  TITLE = {SWAT: Spatial Structure Within and Among Tokens},
}

@ARTICLE{yuan2021contextualized,
  AUTHOR = {Yuan, Liangzhe and Qian, Rui and Cui, Yin and Gong, Boqing and Schroff, Florian and Yang, Ming-Hsuan and Adam, Hartwig and Liu, Ting},
  YEAR = {2022},
  JOURNALTITLE = {CVPR},
  TITLE = {Contextualized Spatio-Temporal Contrastive Learning with Self-Supervision},
}

@ARTICLE{wang2022deformable,
  AUTHOR = {Wang, Jue and Torresani, Lorenzo},
  YEAR = {2022},
  JOURNALTITLE = {CVPR},
  TITLE = {Deformable Video Transformer},
}

@ARTICLE{shvetsova2021everything,
  AUTHOR = {Shvetsova, Nina and Chen, Brian and Rouditchenko, Andrew and Thomas, Samuel and Kingsbury, Brian and Feris, Rogerio and Harwath, David and Glass, James and Kuehne, Hilde},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2112.04446},
  TITLE = {Everything at Once - Multi-modal Fusion Transformer for Video Retrieval},
}

@INPROCEEDINGS{DBLP:conf/eccv/Gabeur0AS20,
  AUTHOR = {Gabeur, Valentin and Sun, Chen and Alahari, Karteek and Schmid, Cordelia},
  EDITOR = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan{-}Michael},
  PUBLISHER = {Springer},
  URL = {https://doi.org/10.1007/978-3-030-58548-8\_13},
  BOOKTITLE = {Computer Vision - {ECCV} 2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part {IV}},
  YEAR = {2020},
  DOI = {10.1007/978-3-030-58548-8\_13},
  PAGES = {214--229},
  SERIES = {Lecture Notes in Computer Science},
  TITLE = {Multi-modal Transformer for Video Retrieval},
  VOLUME = {12349},
}

@INPROCEEDINGS{Recasens_2021_ICCV,
  AUTHOR = {Recasens, Adrià and Luc, Pauline and Alayrac, Jean-Baptiste and Wang, Luyu and Strub, Florian and Tallec, Corentin and Malinowski, Mateusz and Pătrăucean, Viorica and Altché, Florent and Valko, Michal and Grill, Jean-Bastien and van den Oord, Aäron and Zisserman, Andrew},
  BOOKTITLE = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  YEAR = {2021},
  PAGES = {1255--1265},
  TITLE = {Broaden Your Views for Self-Supervised Video Learning},
}

@INPROCEEDINGS{DBLP:conf/nips/AlayracRSARFSDZ20,
  AUTHOR = {Alayrac, Jean{-}Baptiste and Recasens, Adrià and Schneider, Rosalia and Arandjelovic, Relja and Ramapuram, Jason and Fauw, Jeffrey De and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  EDITOR = {Larochelle, Hugo and Ranzato, Marc'Aurelio and Hadsell, Raia and Balcan, Maria{-}Florina and Lin, Hsuan{-}Tien},
  URL = {https://proceedings.neurips.cc/paper/2020/hash/0060ef47b12160b9198302ebdb144dcf-Abstract.html},
  BOOKTITLE = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual},
  YEAR = {2020},
  TITLE = {Self-Supervised MultiModal Versatile Networks},
}

@ARTICLE{li2021towards,
  AUTHOR = {Li, Qing and Gong, Boqing and Cui, Yin and Kondratyuk, Dan and Du, Xianzhi and Yang, Ming-Hsuan and Brown, Matthew},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2112.07074},
  TITLE = {Towards a Unified Foundation Model: Jointly Pre-Training Transformers on Unpaired Images and Text},
}

@INPROCEEDINGS{DBLP:conf/nips/HuangDXCZH21,
  AUTHOR = {Huang, Yu and Du, Chenzhuang and Xue, Zihui and Chen, Xuanyao and Zhao, Hang and Huang, Longbo},
  EDITOR = {Ranzato, Marc'Aurelio and Beygelzimer, Alina and Dauphin, Yann N. and Liang, Percy and Vaughan, Jennifer Wortman},
  URL = {https://proceedings.neurips.cc/paper/2021/hash/5aa3405a3f865c10f420a4a7b55cbff3-Abstract.html},
  BOOKTITLE = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual},
  YEAR = {2021},
  PAGES = {10944--10956},
  TITLE = {What Makes Multi-Modal Learning Better than Single (Provably)},
}

@INPROCEEDINGS{DBLP:conf/cvpr/YeR0W19,
  AUTHOR = {Ye, Linwei and Rochan, Mrigank and Liu, Zhi and Wang, Yang},
  PUBLISHER = {Computer Vision Foundation / {IEEE}},
  URL = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Ye\_Cross-Modal\_Self-Attention\_Network\_for\_Referring\_Image\_Segmentation\_CVPR\_2019\_paper.html},
  BOOKTITLE = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2019, Long Beach, CA, USA, June 16-20, 2019},
  YEAR = {2019},
  DOI = {10.1109/CVPR.2019.01075},
  PAGES = {10502--10511},
  TITLE = {Cross-Modal Self-Attention Network for Referring Image Segmentation},
}

@ARTICLE{yang2022visionlanguage,
  AUTHOR = {Yang, Jinyu and Duan, Jiali and Tran, Son and Xu, Yi and Chanda, Sampath and Chen, Liqun and Zeng, Belinda and Chilimbi, Trishul and Huang, Junzhou},
  YEAR = {2022},
  JOURNALTITLE = {CVPR},
  TITLE = {Vision-Language Pre-Training with Triple Contrastive Learning},
}

@INPROCEEDINGS{NIPS2017_7a98af17,
  AUTHOR = {van den Oord, Aaron and Vinyals, Oriol and kavukcuoglu koray , koray},
  EDITOR = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  PUBLISHER = {Curran Associates, Inc.},
  URL = {https://proceedings.neurips.cc/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf},
  BOOKTITLE = {Advances in Neural Information Processing Systems},
  YEAR = {2017},
  TITLE = {Neural Discrete Representation Learning},
  VOLUME = {30},
}

@INPROCEEDINGS{DBLP:conf/icml/RameshPGGVRCS21,
  AUTHOR = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  EDITOR = {Meila, Marina and Zhang, Tong},
  PUBLISHER = {PMLR},
  URL = {http://proceedings.mlr.press/v139/ramesh21a.html},
  BOOKTITLE = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  YEAR = {2021},
  PAGES = {8821--8831},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {Zero-Shot Text-to-Image Generation},
  VOLUME = {139},
}

@INPROCEEDINGS{DBLP:conf/icml/RadfordKHRGASAM21,
  AUTHOR = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  EDITOR = {Meila, Marina and Zhang, Tong},
  PUBLISHER = {PMLR},
  URL = {http://proceedings.mlr.press/v139/radford21a.html},
  BOOKTITLE = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  YEAR = {2021},
  PAGES = {8748--8763},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {Learning Transferable Visual Models From Natural Language Supervision},
  VOLUME = {139},
}

@INPROCEEDINGS{DBLP:conf/nips/HoJA20,
  AUTHOR = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  EDITOR = {Larochelle, Hugo and Ranzato, Marc'Aurelio and Hadsell, Raia and Balcan, Maria{-}Florina and Lin, Hsuan{-}Tien},
  URL = {https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html},
  BOOKTITLE = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual},
  YEAR = {2020},
  TITLE = {Denoising Diffusion Probabilistic Models},
}

@ARTICLE{saharia2022photorealistic,
  AUTHOR = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S. Sara and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan and Fleet, David J and Norouzi, Mohammad},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-2205.11487},
  TITLE = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
}

@ARTICLE{grill2020bootstrap,
  AUTHOR = {Grill, Jean-Bastien and Strub, Florian and Altch'e, Florent and Tallec, Corentin and Richemond, Pierre H. and Buchatskaya, Elena and Doersch, Carl and Pires, B. '. and Guo, Z. and Azar, M. G. and Piot, Bilal and Kavukcuoglu, K. and Munos, R. and Valko, Michal},
  YEAR = {2020},
  JOURNALTITLE = {neurips},
  TITLE = {Bootstrap your own latent: A new approach to self-supervised Learning},
}

@INPROCEEDINGS{DosovitskiyB0WZ21,
  AUTHOR = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  PUBLISHER = {OpenReview.net},
  URL = {https://openreview.net/forum?id=YicbFdNTTy},
  BOOKTITLE = {9th International Conference on Learning Representations, {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021},
  YEAR = {2021},
  TITLE = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
}

@INPROCEEDINGS{DBLP:conf/icml/ChenK0H20,
  AUTHOR = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey E.},
  PUBLISHER = {PMLR},
  URL = {http://proceedings.mlr.press/v119/chen20j.html},
  BOOKTITLE = {Proceedings of the 37th International Conference on Machine Learning, {ICML} 2020, 13-18 July 2020, Virtual Event},
  YEAR = {2020},
  PAGES = {1597--1607},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {A Simple Framework for Contrastive Learning of Visual Representations},
  VOLUME = {119},
}

@INPROCEEDINGS{DBLP:conf/nips/NagraniYAJSS21,
  AUTHOR = {Nagrani, Arsha and Yang, Shan and Arnab, Anurag and Jansen, Aren and Schmid, Cordelia and Sun, Chen},
  EDITOR = {Ranzato, Marc'Aurelio and Beygelzimer, Alina and Dauphin, Yann N. and Liang, Percy and Vaughan, Jennifer Wortman},
  URL = {https://proceedings.neurips.cc/paper/2021/hash/76ba9f564ebbc35b1014ac498fafadd0-Abstract.html},
  BOOKTITLE = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual},
  YEAR = {2021},
  PAGES = {14200--14213},
  TITLE = {Attention Bottlenecks for Multimodal Fusion},
}

@ARTICLE{oord2018representation,
  AUTHOR = {van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  YEAR = {2018},
  JOURNALTITLE = {arXiv preprint arXiv: Arxiv-1807.03748},
  TITLE = {Representation Learning with Contrastive Predictive Coding},
}

@INPROCEEDINGS{DBLP:conf/icml/ZbontarJMLD21,
  AUTHOR = {Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, Stéphane},
  EDITOR = {Meila, Marina and Zhang, Tong},
  PUBLISHER = {PMLR},
  URL = {http://proceedings.mlr.press/v139/zbontar21a.html},
  BOOKTITLE = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  YEAR = {2021},
  PAGES = {12310--12320},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {Barlow Twins: Self-Supervised Learning via Redundancy Reduction},
  VOLUME = {139},
}

@ARTICLE{DBLP:journals/mt/SulubacakCGREST20,
  AUTHOR = {Sulubacak, Umut and Caglayan, Ozan and Grönroos, Stig{-}Arne and Rouhe, Aku and Elliott, Desmond and Specia, Lucia and Tiedemann, Jörg},
  URL = {https://doi.org/10.1007/s10590-020-09250-0},
  YEAR = {2020},
  DOI = {10.1007/s10590-020-09250-0},
  JOURNALTITLE = {Mach. Transl.},
  NUMBER = {2-3},
  PAGES = {97--147},
  TITLE = {Multimodal machine translation through visuals and speech},
  VOLUME = {34},
}

@INPROCEEDINGS{DBLP:conf/nips/VaswaniSPUJGKP17,
  AUTHOR = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  EDITOR = {Guyon, Isabelle and von Luxburg, Ulrike and Bengio, Samy and Wallach, Hanna M. and Fergus, Rob and Vishwanathan, S. V. N. and Garnett, Roman},
  URL = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  BOOKTITLE = {Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}},
  YEAR = {2017},
  PAGES = {5998--6008},
  TITLE = {Attention is All you Need},
}

@ARTICLE{Cheerla2019,
  AUTHOR = {Cheerla, Anika and Gevaert, Olivier},
  PUBLISHER = {Oxford University Press},
  YEAR = {2019},
  JOURNALTITLE = {Bioinformatics},
  NUMBER = {14},
  PAGES = {i446--i454},
  TITLE = {Deep learning with multimodal representation for pancancer prognosis prediction},
  VOLUME = {35},
}

@ARTICLE{MultiSurv2021,
  AUTHOR = {Vale-Silva, Luı́s A and Rohr, Karl},
  PUBLISHER = {Nature Publishing Group},
  YEAR = {2021},
  JOURNALTITLE = {Scientific Reports},
  NUMBER = {1},
  PAGES = {1--12},
  TITLE = {Long-term cancer survival prediction using multimodal deep learning},
  VOLUME = {11},
}

@INPROCEEDINGS{WideDeepNN2016,
  AUTHOR = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and others},
  BOOKTITLE = {Proceedings of the 1st workshop on deep learning for recommender systems},
  YEAR = {2016},
  PAGES = {7--10},
  TITLE = {Wide \& deep learning for recommender systems},
}

@INPROCEEDINGS{DeepPAMM2022,
  AUTHOR = {Kopper, Philipp and Wiegrebe, Simon and Bischl, Bernd and Bender, Andreas and Rügamer, David},
  ORGANIZATION = {Springer},
  BOOKTITLE = {Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  YEAR = {2022},
  PAGES = {249--261},
  TITLE = {DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex Hazard Structures in Survival Analysis},
}

@INPROCEEDINGS{Poelsterl2020,
  AUTHOR = {Pölsterl, Sebastian and Sarasua, Ignacio and Gutiérrez-Becker, Benjamı́n and Wachinger, Christian},
  ORGANIZATION = {Springer},
  BOOKTITLE = {Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  YEAR = {2019},
  PAGES = {453--464},
  TITLE = {A wide and deep neural network for survival analysis from anatomical shape and tabular clinical data},
}

@ARTICLE{SSDDR2020,
  AUTHOR = {Rügamer, David and Kolb, Chris and Klein, Nadja},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2002.05777},
  TITLE = {Semi-structured deep distributional regression: Combining structured additive models and deep learning},
}

@ARTICLE{GAWWN2016,
  AUTHOR = {Reed, Scott E. and Akata, Zeynep and Mohan, Santosh and Tenka, Samuel and Schiele, Bernt and Lee, Honglak},
  URL = {http://arxiv.org/abs/1610.02454},
  YEAR = {2016},
  EPRINT = {1610.02454},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Learning What and Where to Draw},
}

@ARTICLE{MirrorGAN2019,
  AUTHOR = {Qiao, Tingting and Zhang, Jing and Xu, Duanqing and Tao, Dacheng},
  URL = {http://arxiv.org/abs/1903.05854},
  YEAR = {2019},
  EPRINT = {1903.05854},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {MirrorGAN: Learning Text-to-image Generation by Redescription},
}

@ARTICLE{LAFITE2021,
  AUTHOR = {Zhou, Yufan and Zhang, Ruiyi and Chen, Changyou and Li, Chunyuan and Tensmeyer, Chris and Yu, Tong and Gu, Jiuxiang and Xu, Jinhui and Sun, Tong},
  URL = {https://arxiv.org/abs/2111.13792},
  YEAR = {2021},
  EPRINT = {2111.13792},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {{LAFITE:} Towards Language-Free Training for Text-to-Image Generation},
}

@MISC{MakeAScene2022,
  AUTHOR = {Gafni, Oran and Polyak, Adam and Ashual, Oron and Sheynin, Shelly and Parikh, Devi and Taigman, Yaniv},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2203.13131},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2203.13131},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Artificial Intelligence (cs.AI),Computation and Language (cs.CL),Graphics (cs.GR),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors},
}

@ARTICLE{CogView2021,
  AUTHOR = {Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and Tang, Jie},
  URL = {https://arxiv.org/abs/2105.13290},
  YEAR = {2021},
  EPRINT = {2105.13290},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {CogView: Mastering Text-to-Image Generation via Transformers},
}

@MISC{Evaluation2015,
  AUTHOR = {Theis, Lucas and Oord, Aäron van den and Bethge, Matthias},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1511.01844},
  YEAR = {2015},
  DOI = {10.48550/ARXIV.1511.01844},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {A note on the evaluation of generative models},
}

@ARTICLE{EvaluationComparison2018,
  AUTHOR = {Borji, Ali},
  URL = {http://arxiv.org/abs/1802.03446},
  YEAR = {2018},
  EPRINT = {1802.03446},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Pros and Cons of {GAN} Evaluation Measures},
}

@ARTICLE{InceptionScore2016,
  AUTHOR = {Salimans, Tim and Goodfellow, Ian J. and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  URL = {http://arxiv.org/abs/1606.03498},
  YEAR = {2016},
  EPRINT = {1606.03498},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Improved Techniques for Training GANs},
}

@ARTICLE{InceptionNet2015,
  AUTHOR = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  URL = {http://arxiv.org/abs/1512.00567},
  YEAR = {2015},
  EPRINT = {1512.00567},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Rethinking the Inception Architecture for Computer Vision},
}

@INPROCEEDINGS{FID2017,
  AUTHOR = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  EDITOR = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  PUBLISHER = {Curran Associates, Inc.},
  URL = {https://proceedings.neurips.cc/paper/2017/file/8a1d694707eb0fefe65871369074926d-Paper.pdf},
  BOOKTITLE = {Advances in Neural Information Processing Systems},
  YEAR = {2017},
  TITLE = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
  VOLUME = {30},
}

@MISC{GenerativePrecisionRecall2018,
  AUTHOR = {Sajjadi, Mehdi S. M. and Bachem, Olivier and Lucic, Mario and Bousquet, Olivier and Gelly, Sylvain},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1806.00035},
  YEAR = {2018},
  DOI = {10.48550/ARXIV.1806.00035},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Assessing Generative Models via Precision and Recall},
}

@MISC{ImprovedPrecisionRecall2019,
  AUTHOR = {Kynkäänniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1904.06991},
  YEAR = {2019},
  DOI = {10.48550/ARXIV.1904.06991},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),Neural and Evolutionary Computing (cs.NE),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Improved Precision and Recall Metric for Assessing Generative Models},
}

@ARTICLE{CLIP2021,
  AUTHOR = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  URL = {https://arxiv.org/abs/2103.00020},
  YEAR = {2021},
  EPRINT = {2103.00020},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Learning Transferable Visual Models From Natural Language Supervision},
}

@MISC{GAN2014,
  AUTHOR = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1406.2661},
  YEAR = {2014},
  DOI = {10.48550/ARXIV.1406.2661},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Generative Adversarial Networks},
}

@ARTICLE{GANTextToImage2016,
  AUTHOR = {Reed, Scott E. and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
  URL = {http://arxiv.org/abs/1605.05396},
  YEAR = {2016},
  EPRINT = {1605.05396},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Generative Adversarial Text to Image Synthesis},
}

@ARTICLE{JointRepresentations2016,
  AUTHOR = {Reed, Scott E. and Akata, Zeynep and Schiele, Bernt and Lee, Honglak},
  URL = {http://arxiv.org/abs/1605.05395},
  YEAR = {2016},
  EPRINT = {1605.05395},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Learning Deep Representations of Fine-grained Visual Descriptions},
}

@ARTICLE{StackGAN2016,
  AUTHOR = {Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Huang, Xiaolei and Wang, Xiaogang and Metaxas, Dimitris N.},
  URL = {http://arxiv.org/abs/1612.03242},
  YEAR = {2016},
  EPRINT = {1612.03242},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks},
}

@ARTICLE{AttentionIsAllYouNeed2017,
  AUTHOR = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  URL = {http://arxiv.org/abs/1706.03762},
  YEAR = {2017},
  EPRINT = {1706.03762},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Attention Is All You Need},
}

@ARTICLE{AttnGAN2017,
  AUTHOR = {Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},
  URL = {http://arxiv.org/abs/1711.10485},
  YEAR = {2017},
  EPRINT = {1711.10485},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks},
}

@ARTICLE{DMGAN2019,
  AUTHOR = {Zhu, Minfeng and Pan, Pingbo and Chen, Wei and Yang, Yi},
  URL = {http://arxiv.org/abs/1904.01310},
  YEAR = {2019},
  EPRINT = {1904.01310},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {{DM-GAN:} Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis},
}

@ARTICLE{DFGAN2020,
  AUTHOR = {Tao, Ming and Tang, Hao and Wu, Songsong and Sebe, Nicu and Wu, Fei and Jing, Xiao{-}Yuan},
  URL = {https://arxiv.org/abs/2008.05865},
  YEAR = {2020},
  EPRINT = {2008.05865},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {{DF-GAN:} Deep Fusion Generative Adversarial Networks for Text-to-Image Synthesis},
}

@ARTICLE{DALLE1,
  AUTHOR = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  URL = {https://arxiv.org/abs/2102.12092},
  YEAR = {2021},
  EPRINT = {2102.12092},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Zero-Shot Text-to-Image Generation},
}

@MISC{VAE2013,
  AUTHOR = {Kingma, Diederik P and Welling, Max},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/1312.6114},
  YEAR = {2013},
  DOI = {10.48550/ARXIV.1312.6114},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Auto-Encoding Variational Bayes},
}

@ARTICLE{weng2018VAE,
  AUTHOR = {Weng, Lilian},
  URL = {https://lilianweng.github.io/posts/2018-08-12-vae/},
  YEAR = {2018},
  JOURNALTITLE = {lilianweng.github.io},
  TITLE = {From Autoencoder to Beta-VAE},
}

@ARTICLE{VQVAE2017,
  AUTHOR = {van den Oord, Aäron and Vinyals, Oriol and Kavukcuoglu, Koray},
  URL = {http://arxiv.org/abs/1711.00937},
  YEAR = {2017},
  EPRINT = {1711.00937},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Neural Discrete Representation Learning},
}

@MISC{UnderstandingVQVAE,
  AUTHOR = {Snell, Charlie},
  YEAR = {2021},
  HOWPUBLISHED = {\url{https://ml.berkeley.edu/blog/posts/vq-vae/}},
  NOTE = {Accessed: 2022-09-12},
  TITLE = {Understanding VQ-VAE},
}

@ARTICLE{BPE2015,
  AUTHOR = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  URL = {http://arxiv.org/abs/1508.07909},
  YEAR = {2015},
  EPRINT = {1508.07909},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Neural Machine Translation of Rare Words with Subword Units},
}

@ARTICLE{Diffusion2015,
  AUTHOR = {Sohl{-}Dickstein, Jascha and Weiss, Eric A. and Maheswaranathan, Niru and Ganguli, Surya},
  URL = {http://arxiv.org/abs/1503.03585},
  YEAR = {2015},
  EPRINT = {1503.03585},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
}

@ARTICLE{DenoisingDiffusion2020,
  AUTHOR = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  URL = {https://arxiv.org/abs/2006.11239},
  YEAR = {2020},
  EPRINT = {2006.11239},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Denoising Diffusion Probabilistic Models},
}

@ARTICLE{weng2021diffusion,
  AUTHOR = {Weng, Lilian},
  URL = {https://lilianweng.github.io/posts/2021-07-11-diffusion-models/},
  YEAR = {2021},
  JOURNALTITLE = {lilianweng.github.io},
  TITLE = {What are diffusion models?},
}

@MISC{DALLE2,
  AUTHOR = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2204.06125},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2204.06125},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Hierarchical Text-Conditional Image Generation with CLIP Latents},
}

@MISC{Imagen2022,
  AUTHOR = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S. Sara and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan and Fleet, David J and Norouzi, Mohammad},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2205.11487},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2205.11487},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
}

@MISC{Parti2022,
  AUTHOR = {Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and Hutchinson, Ben and Han, Wei and Parekh, Zarana and Li, Xin and Zhang, Han and Baldridge, Jason and Wu, Yonghui},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2206.10789},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2206.10789},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
}

@ARTICLE{T5XXL2019,
  AUTHOR = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  URL = {http://arxiv.org/abs/1910.10683},
  YEAR = {2019},
  EPRINT = {1910.10683},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
}

@ARTICLE{VitVQGAN2021,
  AUTHOR = {Yu, Jiahui and Li, Xin and Koh, Jing Yu and Zhang, Han and Pang, Ruoming and Qin, James and Ku, Alexander and Xu, Yuanzhong and Baldridge, Jason and Wu, Yonghui},
  URL = {https://arxiv.org/abs/2110.04627},
  YEAR = {2021},
  EPRINT = {2110.04627},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Vector-quantized Image Modeling with Improved {VQGAN}},
}

@MISC{VQGANCLIP2022,
  AUTHOR = {Crowson, Katherine and Biderman, Stella and Kornis, Daniel and Stander, Dashiell and Hallahan, Eric and Castricato, Louis and Raff, Edward},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2204.08583},
  YEAR = {2022},
  DOI = {10.48550/ARXIV.2204.08583},
  KEYWORDS = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance},
}

@MISC{Midjourney,
  AUTHOR = {Midjourney},
  YEAR = {2022},
  HOWPUBLISHED = {\url{https://www.midjourney.com/}},
  NOTE = {Accessed: 2022-09-12},
  TITLE = {Midjourney},
}

@ARTICLE{LatentDiffusion2021,
  AUTHOR = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  URL = {https://arxiv.org/abs/2112.10752},
  YEAR = {2021},
  EPRINT = {2112.10752},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {High-Resolution Image Synthesis with Latent Diffusion Models},
}

@MISC{StableDiffusion2022,
  AUTHOR = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  YEAR = {2022},
  HOWPUBLISHED = {\url{https://github.com/CompVis/stable-diffusion}},
  NOTE = {Accessed: 2022-09-12},
  TITLE = {StableDiffusion},
}

@ARTICLE{mishkin2022risks,
  AUTHOR = {Mishkin, Pamela and Ahmad, Lama and Brundage, Miles and Krueger, Gretchen and Sastry, Girish},
  URL = {[https://github.com/openai/dalle-2-preview/blob/main/system-card.md](https://github.com/openai/dalle-2-preview/blob/main/system-card.md)},
  YEAR = {2022},
  TITLE = {DALL·E 2 Preview - Risks and Limitations},
}

@INPROCEEDINGS{cornia2020m2,
  AUTHOR = {Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  YEAR = {2020},
  TITLE = {{Meshed-Memory Transformer for Image Captioning}},
}

@ARTICLE{bordes2020incorporating,
  AUTHOR = {Bordes, Patrick and Zablocki, Eloi and Soulier, Laure and Piwowarski, Benjamin and Gallinari, Patrick},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2002.02734},
  TITLE = {Incorporating visual semantics into sentence representations within a grounded space},
}

@INPROCEEDINGS{ramesh2021dalle,
  AUTHOR = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  EDITOR = {Meila, Marina and Zhang, Tong},
  PUBLISHER = {PMLR},
  URL = {https://proceedings.mlr.press/v139/ramesh21a.html},
  BOOKTITLE = {Proceedings of the 38th International Conference on Machine Learning},
  YEAR = {2021},
  FILE = {http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf},
  PAGES = {8821--8831},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {Zero-Shot Text-to-Image Generation},
  VOLUME = {139},
}

@ARTICLE{nichol2021glide,
  AUTHOR = {Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  URL = {https://arxiv.org/abs/2112.10741},
  YEAR = {2021},
  EPRINT = {2112.10741},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {{GLIDE:} Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
}

@ARTICLE{bommasani2021opportunities,
  AUTHOR = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2108.07258},
  TITLE = {On the opportunities and risks of foundation models},
}

@ARTICLE{ramesh2022hierarchical,
  AUTHOR = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  YEAR = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2204.06125},
  TITLE = {Hierarchical Text-Conditional Image Generation with CLIP Latents. 2022},
}

@INPROCEEDINGS{tian2020contrastive,
  AUTHOR = {Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  ORGANIZATION = {Springer},
  BOOKTITLE = {European conference on computer vision},
  YEAR = {2020},
  PAGES = {776--794},
  TITLE = {Contrastive multiview coding},
}

@ARTICLE{SwAV,
  AUTHOR = {Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  URL = {https://arxiv.org/abs/2006.09882},
  YEAR = {2020},
  EPRINT = {2006.09882},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
}

@ARTICLE{ImageT,
  AUTHOR = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  URL = {https://arxiv.org/abs/2010.11929},
  YEAR = {2020},
  EPRINT = {2010.11929},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
}

@INPROCEEDINGS{DeepCorrSurv,
  AUTHOR = {Yao, Jiawen and Zhu, Xinliang and Zhu, Feiyun and Huang, Junzhou},
  PUBLISHER = {Springer International Publishing},
  BOOKTITLE = {Medical Image Computing and Computer-Assisted Intervention − MICCAI 2017},
  YEAR = {2017},
  ISBN = {978-3-319-66185-8},
  PAGES = {406--414},
  TITLE = {Deep Correlational Learning for Survival Prediction from Multi-modality Data},
}

@ARTICLE{Law2019,
  AUTHOR = {Law, Stephen and Paige, Brooks and Russell, Chris},
  PUBLISHER = {Association for Computing Machinery ({ACM})},
  URL = {https://doi.org/10.1145%2F3342240},
  YEAR = {2019},
  DOI = {10.1145/3342240},
  JOURNALTITLE = {{ACM} Transactions on Intelligent Systems and Technology},
  NUMBER = {5},
  PAGES = {1--19},
  TITLE = {Take a Look Around},
  VOLUME = {10},
}

@ARTICLE{Jean2016,
  AUTHOR = {Jean, Neal and Burke, Marshall and Xie, Michael and Davis, W. Matthew and Lobell, David B. and Ermon, Stefano},
  URL = {https://www.science.org/doi/abs/10.1126/science.aaf7894},
  YEAR = {2016},
  DOI = {10.1126/science.aaf7894},
  EPRINT = {https://www.science.org/doi/pdf/10.1126/science.aaf7894},
  JOURNALTITLE = {Science},
  NUMBER = {6301},
  PAGES = {790--794},
  TITLE = {Combining satellite imagery and machine learning to predict poverty},
  VOLUME = {353},
}

@ARTICLE{Gebru2017,
  AUTHOR = {Gebru, Timnit and Krause, Jonathan and Wang, Yilun and Chen, Duyun and Deng, Jia and Aiden, Erez and Fei-Fei, Li},
  YEAR = {2017},
  DOI = {10.1073/pnas.1700035114},
  JOURNALTITLE = {Proceedings of the National Academy of Sciences},
  PAGES = {201700035},
  TITLE = {Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States},
  VOLUME = {114},
}

@INPROCEEDINGS{DeepGPYou2017,
  AUTHOR = {You, Jiaxuan and Li, Xiaocheng and Low, Melvin and Lobell, David and Ermon, Stefano},
  LOCATION = {San Francisco, California, USA},
  PUBLISHER = {AAAI Press},
  BOOKTITLE = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
  YEAR = {2017},
  PAGES = {4559--4565},
  SERIES = {AAAI'17},
  TITLE = {Deep Gaussian Process for Crop Yield Prediction Based on Remote Sensing Data},
}

@ARTICLE{Sirko2021,
  AUTHOR = {Sirko, Wojciech and Kashubin, Sergii and Ritter, Marvin and Annkah, Abigail and Bouchareb, Yasser Salah Eddine and Dauphin, Yann N. and Keysers, Daniel and Neumann, Maxim and Cissé, Moustapha and Quinn, John},
  URL = {https://arxiv.org/abs/2107.12283},
  YEAR = {2021},
  EPRINT = {2107.12283},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Continental-Scale Building Detection from High Resolution Satellite Imagery},
}

@ARTICLE{rosset2020turing,
  AUTHOR = {Rosset, Corby},
  YEAR = {2020},
  JOURNALTITLE = {Microsoft Blog},
  NUMBER = {2},
  TITLE = {Turing-NLG: A 17-billion-parameter language model by Microsoft},
  VOLUME = {1},
}

@ARTICLE{gao2020pile,
  AUTHOR = {Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  YEAR = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2101.00027},
  TITLE = {The pile: An 800gb dataset of diverse text for language modeling},
}

@INPROCEEDINGS{zhu2015aligning,
  AUTHOR = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  BOOKTITLE = {Proceedings of the IEEE international conference on computer vision},
  YEAR = {2015},
  PAGES = {19--27},
  TITLE = {Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
}

@INCOLLECTION{fellbaum2010wordnet,
  AUTHOR = {Fellbaum, Christiane},
  PUBLISHER = {Springer},
  BOOKTITLE = {Theory and applications of ontology: computer applications},
  YEAR = {2010},
  PAGES = {231--243},
  TITLE = {WordNet},
}

@ARTICLE{krizhevsky2009learning,
  AUTHOR = {Krizhevsky, Alex and Hinton, Geoffrey and others},
  PUBLISHER = {Toronto, ON, Canada},
  YEAR = {2009},
  TITLE = {Learning multiple layers of features from tiny images},
}

@ARTICLE{hinton2015distilling,
  AUTHOR = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  YEAR = {2015},
  JOURNALTITLE = {arXiv preprint arXiv:1503.02531},
  NUMBER = {7},
  TITLE = {Distilling the knowledge in a neural network},
  VOLUME = {2},
}

@INPROCEEDINGS{sun2017revisiting,
  AUTHOR = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  BOOKTITLE = {Proceedings of the IEEE international conference on computer vision},
  YEAR = {2017},
  PAGES = {843--852},
  TITLE = {Revisiting unreasonable effectiveness of data in deep learning era},
}

@ARTICLE{schuhmann2021laion,
  AUTHOR = {Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  YEAR = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2111.02114},
  TITLE = {Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
}

@INPROCEEDINGS{torralba2011unbiased,
  AUTHOR = {Torralba, Antonio and Efros, Alexei A},
  ORGANIZATION = {IEEE},
  BOOKTITLE = {CVPR 2011},
  YEAR = {2011},
  PAGES = {1521--1528},
  TITLE = {Unbiased look at dataset bias},
}

@INPROCEEDINGS{pont2020connecting,
  AUTHOR = {Pont-Tuset, Jordi and Uijlings, Jasper and Changpinyo, Soravit and Soricut, Radu and Ferrari, Vittorio},
  ORGANIZATION = {Springer},
  BOOKTITLE = {European conference on computer vision},
  YEAR = {2020},
  PAGES = {647--664},
  TITLE = {Connecting vision and language with localized narratives},
}

@INPROCEEDINGS{zhou2017scene,
  AUTHOR = {Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  BOOKTITLE = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  YEAR = {2017},
  PAGES = {633--641},
  TITLE = {Scene parsing through ade20k dataset},
}

@ARTICLE{young2014image,
  AUTHOR = {Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  PUBLISHER = {MIT Press},
  YEAR = {2014},
  JOURNALTITLE = {Transactions of the Association for Computational Linguistics},
  PAGES = {67--78},
  TITLE = {From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  VOLUME = {2},
}

@ARTICLE{kuznetsova2020open,
  AUTHOR = {Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  PUBLISHER = {Springer},
  YEAR = {2020},
  JOURNALTITLE = {International Journal of Computer Vision},
  NUMBER = {7},
  PAGES = {1956--1981},
  TITLE = {The open images dataset v4},
  VOLUME = {128},
}

@ONLINE{LocNarWeb,
  AUTHOR = {Website},
  URL = {https://google.github.io/localized-narratives},
  YEAR = {2020},
  TITLE = {Localized Narratives Data and Visualization},
  URLDATE = {2022-06-26},
}

@ARTICLE{krishna2017visual,
  AUTHOR = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  PUBLISHER = {Springer},
  YEAR = {2017},
  JOURNALTITLE = {International journal of computer vision},
  NUMBER = {1},
  PAGES = {32--73},
  TITLE = {Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  VOLUME = {123},
}

@ARTICLE{Vaswani2017,
  AUTHOR = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  YEAR = {2017},
  EPRINT = {1706.03762},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1706.03762v5:PDF},
  KEYWORDS = {cs.CL,cs.LG},
  TITLE = {Attention Is All You Need},
}

@ARTICLE{Brown2020,
  AUTHOR = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  YEAR = {2020},
  EPRINT = {2005.14165},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2005.14165v4:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Language Models are Few-Shot Learners},
}

@ARTICLE{Dosovitskiy2020,
  AUTHOR = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  YEAR = {2020},
  EPRINT = {2010.11929},
  EPRINTCLASS = {cs.CV},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2010.11929v2:PDF},
  KEYWORDS = {cs.CV,cs.AI,cs.LG},
  TITLE = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
}

@INPROCEEDINGS{Strubell2019,
  AUTHOR = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  LOCATION = {Florence, Italy},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/P19-1355},
  BOOKTITLE = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  YEAR = {2019},
  DOI = {10.18653/v1/P19-1355},
  PAGES = {3645--3650},
  TITLE = {Energy and Policy Considerations for Deep Learning in {NLP}},
}

@ARTICLE{Perez2021,
  AUTHOR = {Perez, Ethan and Kiela, Douwe and Cho, Kyunghyun},
  YEAR = {2021},
  EPRINT = {2105.11447},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2105.11447v1:PDF},
  KEYWORDS = {cs.CL,cs.LG,stat.ML},
  TITLE = {True Few-Shot Learning with Language Models},
}

@ARTICLE{Schick2020,
  AUTHOR = {Schick, Timo and Schütze, Hinrich},
  YEAR = {2020},
  EPRINT = {2001.07676},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/2001.07676v3:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference},
}

